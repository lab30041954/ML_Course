{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21275a45-665e-4241-992a-e7c2184da6bf",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lab30041954/ML_IESE_Course/blob/main/%5BML-06%5D%20Logistic%20regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-EXmBTIw-hb"
   },
   "source": [
    "# [ML-01] Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of **artificial intelligence** (AI) is create agents that perform certain tasks in an \"intelligent\" way. An **AI agent** can be something physical, like a robot that sweeps the floor, or a software app, like a model that classifies the potential customers of a lending institution as good or bad creditors.\n",
    "\n",
    "**Machine learning** (ML) takes place when the AI agent learns from data how to perform its task. We operationalize the learning process as follows. We design a **model**, which can be as simple as a single equation, or as complex as **Gemini 2.5**. This model has a set of **parameters**. The number of parameters can be high (more than one trillion in some large language models), so it is often unclear what their specific role is. Then the learning process consists in using the data to find the **optimal values** for the parameters. \n",
    "\n",
    "Instead of talking about \"learning\", a statistician would say that he is **fitting** the model to the data, or **estimating** the parameters of the model. This terminology is used in one of the Python libraries used in this course, **scikit-learn**. \n",
    "\n",
    "Finding the optimal parameter values is also called **training**. The data used for training the model are then the **training data**. A major issue with training a model is that the parameter values that are optimal on the training data may be suboptimal on data that have not been involved in the training, so that the model underperforms in real applications. This is the **overfitting** problem.\n",
    "\n",
    "To assess the potential overfitting, the model is tested on different data, which are then called **test data**. This is **model validation**. Validation is needed for models whose complexity allows them to overfit the data. Overfitting is a fact of life for many ML algorithms, *e.g*. for those used to develop **neural network models**. So, validation is integrated in the learning process for these models.\n",
    "\n",
    "This course is restricted to **supervised learning**. Roughly speaking, this is what the statisticians call **prediction**, that is, the description of one variable ($Y$) in terms of other variables (the $X$'s). In the ML context, $Y$ is called the **target**, and the $X$'s are called the **features**. The units (they can be customers, products, etc) on which the features and the target are observed are called **samples** (this term has a different meaning in statistics).\n",
    "\n",
    "The term **regression** applies to the prediction of a (more or less continuous) numeric target, and the term **classification** to the prediction of a categorical target. In **binary classification**, there are only two target values or **classes**, while, in **multi-class classification**, there can be three or more. A **classifier**, or classification model, predicts a probability for every class.\n",
    "\n",
    "In an example of regression, we may try to predict the price of a house from a set of attributes of that house. In one of classification, whether a customer is going to quit our company, from his/her demographics plus some measures of customer activity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package **scikit-learn** (`sklearn` in the code) is a machine learning toolkit, built on top of NumPy, SciPy and Matplotlib. To get an idea of the hierarchy and the contents of the various scikit-learn subpackages, the best source is the **scikit-learn API Reference** (`scikit-learn.org/stable/modules/classes.html`). Some of these subpackages are used in this course: `linear_model`, `tree`, `metrics`, `ensemble`, etc.\n",
    "\n",
    "The subpackages that we use for supervised learning contain a collection of **estimator classes**, which allow us to create and apply predictive models. In this course, we use a number of these classes: `LinearRegression()`, `LogisticRegression()`, `DecisionTreeClassifier()`, etc. In Python, a **class** is like an object constructor, or a \"blueprint\" for creating objects. Even if they may look intimidating at first sight, it is very easy, in practice, to pick a class from a Python package and create an object of that class, as you will see in the examples of this course.\n",
    "\n",
    "Working with scikit-learn, you may receive a **warning** from time to time. Note that a warning is not the same as an **error message**. An error message stops the execution of your command, while a warning does not. Most of the warnings will tell you nothing of interest, but a few ones contain relevant information, so it is recommended to take a look at them with the corner of your eye.\n",
    "\n",
    "To train a supervised learning method in scikit-learn, you have to specify a (1D) **target vector** `y` and a (2D) **feature matrix** `X`. In regression, both `X` and `y` have to be of numeric or Boolean type, but, in classification, `y` can be a string vector. Both NumPy arrays and Pandas data containers are accepted, but the scikit-learn methods always return NumPy arrays."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification bascis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification** is the prediction of a **categorical target**. The target values are called **classes**, and they are indicated in the training data by **class labels**. In a classification model, the **predicted class** is obtained in two steps:\n",
    "\n",
    "* For every sample, the model calculates a set of **predicted class probabilities**, one for each class. The different types of models differ in the way in which they calculate these probabilities.\n",
    "\n",
    "* The **predicted class** is the one with higher probability.\n",
    "\n",
    "This is the **default prediction** method. When this approach is used, the class probabilities may be hidden, so the model is presented as if it were making the predictions directly. But departure from the default is not rare in many real-world applications.\n",
    "\n",
    "An important case is **class imbalance**. This occurs when the proportion of training units in one class is significantly different from the proportion of training units in the other classes. This will appear in the in this lecture in a casual way, and will be discussed more specifically later.\n",
    "\n",
    "In **binary classification**, there are two classes, typically called **positive** and **negative**. Use the names positive/negative so that they favor your intuition. Mind that, if you leave this to the computer, it may call positive what you regard as negative.\n",
    "\n",
    "In a binary setting, managing two complementary probabilities is redundant, so we can focus on the positive class probability. This probability, called the **predictive score**, is used for management purposes in many business applications (*e.g*. in credit scoring).\n",
    "\n",
    "In the default binary prediction, a sample would be classified as positive when its score exceeds 0.5. But you may wish to replace 0.5 by a different **threshold** value. In a business application, the choice of the threshold may be based on a **cost/benefit analysis**. It is not hard to (approximately) find the **optimal threshold** for a user-specified cost matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation of a classifier is, explicitly or implicitly, based on a **confusion matrix**, obtained by cross tabulation of the actual classes and the predicted classes. There is not a universal consensus on what to place in the rows and what in the columns. We use the same convention as the scikit-learn manual, with the actual class in the rows and the predicted class in the columns.\n",
    "\n",
    "In a binary setting, a visual inspection of the confusion matrix is always recommended. It will probably help you to decide whether the model is going to be useful. In many cases, it is practical to examine the model performance separately on the actual positives and negatives.\n",
    "\n",
    "The four cells of the confusion matrix are referred to as **true positive** (actual positives predicted as positives), **false positive** (actual negatives predicted as positives), **true negative** (actual negatives predicted as negatives) and **false negative** (actual positives predicted as negatives).\n",
    "\n",
    "<br/>\n",
    "\n",
    "| | Predicted negative | Predicted positive |\n",
    "| --- | :---: | :---: |\n",
    "| **Actual negative** | TN | FP |\n",
    "| **Actual positive** | FN | TP |\n",
    "\n",
    "<br/>\n",
    "\n",
    "The proportion of samples classified in the right way, that is, those for which the actual and the predicted values coincide, is called the **accuracy**,\n",
    "\n",
    "$$\\textrm{Accuracy} = \\frac{\\textrm{TN}+\\textrm{TP}} {\\textrm{TN}+\\textrm{FP}+\\textrm{FN}+\\textrm{TP}}\\thinspace.$$\n",
    "\n",
    "The accuracy can be calculated directly, or extracted from the confusion matrix, as the sum of the diagonal terms divided by the sum of all terms. Although it looks as the obvious metric for the evaluation of a classifier, the accuracy is not always adequate, specially when the training data present class imbalance. For instance, if you have a 90% of negative training units, classifying all the training units as negative gives you 90% accuracy (you don't need machine learning for that!).\n",
    "\n",
    "In a business context, a visual inspection of the confusion matrix is always recommended. In many cases, it is useful to examine the performance of the classifier separately on the actual positives and the actual negatives. Various metrics can be extracted from the confusion matrix, but this course only uses two:\n",
    "\n",
    "* The **true positive rate** is the proportion of right classification among the actual positives,\n",
    "\n",
    "$$\\textrm{TP\\ rate} = \\frac{\\textrm{TP}} {\\textrm{TP}+\\textrm{FN}}\\thinspace.$$\n",
    "\n",
    "* The **false positive rate** is the proportion of wrong classification among the actual negatives,\n",
    "\n",
    "$$\\textrm{FP\\ rate} = \\frac{\\textrm{FP}} {\\textrm{FP}+\\textrm{TN}}\\thinspace.$$\n",
    "\n",
    "A good model should have both a high true positive rate and a low false positive rate low. The relative importance given to these statistics depends on the actual application. Their advantage is that they are still valid when the proportion of positives in the training data has been artificially inflated, because they are calculated separately on the actual positives and the actual negatives. This may look strange, but it is common practice under class imbalance. When the proportion of positives is inflated, the training data cannot be taken as representative of any population, and the accuracy derived from the confusion matrix cannot be extrapolated to the real world.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The maths of machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the parameter values learned are optimal, meaning that a certain **loss function** attains its minimum value. Typically, the loss function in a classification model is the **average cross-entropy**, a formula extracted from information theory. For every data unit, the cross-entropy is the negative logarithm of the predicted class probability of the actual class of that sample. scikit-learn uses binary logs, as in information theory, but other libraries, like **Keras**, use natural logs. You should not be concerned by this, because you don't really use these cross-entropy values, they are just part of mathematical apparatus.\n",
    "\n",
    "Let us show, explicitly, how the cross-entropy is calculated in a binary setting, using natural logs:\n",
    "\n",
    "* Take a positive sample whose predicted class probabilities are $0.2$ (for the negative class) and $0.8$ (for the positive class). Then, the cross-entropy for this sample is $-\\log\\thinspace 0.8 = 0.2231$. \n",
    "\n",
    "* Take a negative sample whose class probabilities are $0.7$ and $0.3$, respectively. Then, the cross-entropy for this sample is $-\\log\\thinspace 0.7 = 0.3567$. \n",
    "\n",
    "The average of these values for the all the training units is the loss. What is the logic of using this loss function? As shown in Figure 1, the negative log function is decreasing , with the minimum value $-\\log\\thinspace 1 = 0$, so that by minimizing the cross-entropy, we are pushing the class probabilities of the negative units towards the pair $(1, 0)$ and those of the positive units towards the pair $(0, 1)$, that would be the perfect predictions.\n",
    "\n",
    "![](https://raw.githubusercontent.com/lab30041954/Figures/main/neglog.png)\n",
    "\n",
    "We don't have a closed formula to calculate the optimal parameter values. The optimal parameter values are obtained by means of an **optimization algorithm**, called the **solver**, which starts with a set of random parameter values and changes these values in a sequence of steps or **iterations**, decreasing the loss at every step. The iterative process goes on until the loss falls below a certain **tolerance** or until a **maximum number of iterations** has been attained. Then we say that the process has achieved **convergence**. When the feature scales are diverse, this process is slower, and the number of iterations needed to converge is higher. We will see this in the examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic regression** is one of the simplest classification methods. In spite of its name, it is a classification method, not a regression method. The explanation is that logistic regression was created by statisticians, and regression does not mean the same in statistics as in machine learning.\n",
    "\n",
    "The class probabilities are calculated as follows. Suppose that $k$ numeric features $X_1, \\dots, X_k$ are used to predict a target with $m$ classes. The logistic regression model is based on a set of linear equations, \n",
    "\n",
    "$$z = b_0 + b_1X_1 + b_2X_2 + \\cdots + b_kX_k,$$\n",
    "\n",
    "one for each class. The values $z_1, \\dots, z_m$, which are called **logits**, are transformed in class probabilities $p_1, \\dots, p_m$ by means of the **softmap function**\n",
    "\n",
    "$$p_i = \\frac{\\exp(z_i)}{\\exp(z_1) + \\cdots + \\exp(z_m)}.$$\n",
    "\n",
    "Note that, since $p_1 + \\cdots + p_m = 1$, one of the equations can be obtained from the rest, so the weights, and consequently the logits are not uniquely determined. Don't worry about this, Python will take care and, in practice, the logits are never extracted explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example - The churn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term **churn** is used in marketing to refer to a customer leaving the company in favor of a competitor. Churning is a common concern of **Customer Relationship Management** (CRM). A key step in proactive churn management is to predict whether a customer is likely to churn, since an early detection of the potential churners helps to plan the retention campaigns.\n",
    "\n",
    "This example presents a churn model based on a **logistic regression model**, for a company called *Omicron Mobile*, which provides mobile phone services. The data set is based on a random sample of 5,000 customers whose accounts were still alive by September 30, and have been monitored during the fourth quarter. 968 of those customers churned during the fourth quarter, a **churning rate** of 19.4%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables included in the data set (file `churn.csv`) are:\n",
    "\n",
    "* `id`, a customer ID (the phone number).\n",
    "\n",
    "* `aclentgh`, the number of days the account has been active at the beginning of the period monitored.\n",
    "\n",
    "* `intplan`, a dummy for having an international plan.\n",
    "\n",
    "* `dataplan`, a dummy for having a data plan.\n",
    "\n",
    "* `ommin`, the total minutes call to any Omicron mobile phone number, voicemail or national landline.\n",
    "\n",
    "* `omcall`, the total number of calls to any Omicron mobile phone number, voicemail or national landline.\n",
    "\n",
    "* `otmin`, the total minutes call to other mobile networks.\n",
    "\n",
    "* `otcall`, the total number of calls to other networks.\n",
    "\n",
    "* `ngmin`, the total minutes call to nongeographic numbers. Nongeographic numbers, such as UK numbers 0844 or 0871, are often helplines for organizations like banks, insurance companies, utilities and charities.\n",
    "\n",
    "* `ngcall`, the total number of calls to nongeographic numbers.\n",
    "\n",
    "* `imin`, the total minutes in international calls.\n",
    "\n",
    "* `icall`, the total international calls.\n",
    "\n",
    "* `cuscall`, the number of calls to customer service.\n",
    "\n",
    "* `churn`, a dummy for churning.\n",
    "\n",
    "All the data are from the third quarter except the last variable.\n",
    "\n",
    "Source: MA Canela, I Alegre & A Ibarra (2019), *Quantitative Methods for Management*, Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1. Develop a logistic regression model to calculate a **churn score**, that is, an estimate of the probability of churning, for each customer.\n",
    "\n",
    "Q2. How is the distribution of churn scores? Is it different for the churners and the non-churners?\n",
    "\n",
    "Q3. Set an adequate **threshold** for the churn score and apply it to decide which customers are potential churners. What is the **true positive rate**? And the **false positive rate**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdF-IBvFxBaI"
   },
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We manage the data set as a **Pandas data frame**. First, we import Pandas in the usual way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "lP_LdOvFxPzQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, we use remote data sources. The source files are stored in a GitHub repository. In Pandas, remote source files work the same as local files, the only difference being in the path. For the source files of our examples, the path is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'https://raw.githubusercontent.com/lab30041954/Data/main/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This path can be joined to the file name, as path + filename (in Python, the plus sign + can be used to concatenate strings). Now, we import the data, as a Pandas data frame, with the Pandas function read_csv(). We take the first column in the source file (`id`) as the index (with the argument `index_col=0`). Don't forget that the path must match the current location of the data source file, either local or remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'churn.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAmxhUPCxYk3"
   },
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df` is a Pandas data frame. In the report printed by the method `.info()`, we don't find anything unexpected. There are no missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NCqX_SkixcTb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5000 entries, 409-8978 to 444-8504\n",
      "Data columns (total 13 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   aclength  5000 non-null   int64  \n",
      " 1   intplan   5000 non-null   int64  \n",
      " 2   dataplan  5000 non-null   int64  \n",
      " 3   ommin     5000 non-null   float64\n",
      " 4   omcall    5000 non-null   int64  \n",
      " 5   otmin     5000 non-null   float64\n",
      " 6   otcall    5000 non-null   int64  \n",
      " 7   ngmin     5000 non-null   float64\n",
      " 8   ngcall    5000 non-null   int64  \n",
      " 9   imin      5000 non-null   float64\n",
      " 10  icall     5000 non-null   int64  \n",
      " 11  cuscall   5000 non-null   int64  \n",
      " 12  churn     5000 non-null   int64  \n",
      "dtypes: float64(4), int64(9)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXDXg8EZxifO"
   },
   "source": [
    "### Q1. Logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use scikit-learn to obtain our logistic regression model. We start by creating a **target vector** `y` and a **feature matrix** `X`. In this example, the target vector is the last column (`churn`), and the feature matrix is made of the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xUHKSBehxlnE"
   },
   "outputs": [],
   "source": [
    "y = df['churn']\n",
    "X = df.drop(columns='churn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we use the class `LogisticRegression()`, from the scikit-learn subpackage `linear_model`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QQWjmHM1xpu1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimator will be an **instance** of this class, that is, an object which applies the logistic regression technique. We call this estimator `clf` (to remind us that it is a classifier). Instead of accepting the default parameter values, we increase the **maximum number of iterations**. Using the default `max_iter=100` would have raised a warning indicating that the optimization process has not converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn, irrespective of the type of estimator, three basic methods, namely `.fit()`, `.predict()` and `.score()`, are available. The method `.fit()` performs the **training**, that is, it finds the logistic regression model that works best for the data. In practice, this means that the parameter values are those for which the loss (the average cross-entropy) is minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GcT2v0JsxsH-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=2000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=2000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=2000)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.score()` performs an overall evaluation of the model. For a classification model, this is the accuracy. We round it to three digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "RvRCViU5xuB6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(clf.score(X, y), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first sight, 84.2% of right prediction may look like a feat, but not so if we take into account, the degree of **class imbalance** in these data. With only 19.4% positive cases, 80.6% accuracy can be obtained in a trivial way. So let us take a closer look at the performance of this model.\n",
    "\n",
    "As given by the method `.predict()`, the **predicted target values** are obtained as discussed in our general introduction to classification models. In this example, this means that two complementary class probabilities are calculated for every customer, one for churning (`y == 1`) and one for not churning (`y == 0`). These probabilities can be extracted with the method `.predict_proba()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hkdouwalxw4A"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9527001 , 0.0472999 ],\n",
       "       [0.96875544, 0.03124456],\n",
       "       [0.72551191, 0.27448809],\n",
       "       ...,\n",
       "       [0.871238  , 0.128762  ],\n",
       "       [0.40603354, 0.59396646],\n",
       "       [0.17404007, 0.82595993]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mind that Python sorts the classes alphabetically. In the binary case, this means that the negative class comes first. The probability of the positive class is taken as a **predictive score** (as in credit scoring). Then the predicted class is chosen based on a **threshold value**: the predicted class is positive when the score exceeds the threshold, and negative otherwise. \n",
    "\n",
    "The scores are extracted as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KjIQU48bx4c-"
   },
   "outputs": [],
   "source": [
    "df['score'] = clf.predict_proba(X)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have added the scores as a column to our data set, which is just an option, since we can also manage it as a separate vector. The actual class and the predictive score are now the last two columns in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YtZNK74Ux7eN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>churn</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>409-8978</th>\n",
       "      <td>0</td>\n",
       "      <td>0.047300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444-7077</th>\n",
       "      <td>0</td>\n",
       "      <td>0.031245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401-9132</th>\n",
       "      <td>0</td>\n",
       "      <td>0.274488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409-2971</th>\n",
       "      <td>0</td>\n",
       "      <td>0.131657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431-5175</th>\n",
       "      <td>0</td>\n",
       "      <td>0.069270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390-2408</th>\n",
       "      <td>0</td>\n",
       "      <td>0.572826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407-6398</th>\n",
       "      <td>0</td>\n",
       "      <td>0.267134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444-7620</th>\n",
       "      <td>1</td>\n",
       "      <td>0.128762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352-4885</th>\n",
       "      <td>1</td>\n",
       "      <td>0.593966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444-8504</th>\n",
       "      <td>1</td>\n",
       "      <td>0.825960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          churn     score\n",
       "id                       \n",
       "409-8978      0  0.047300\n",
       "444-7077      0  0.031245\n",
       "401-9132      0  0.274488\n",
       "409-2971      0  0.131657\n",
       "431-5175      0  0.069270\n",
       "...         ...       ...\n",
       "390-2408      0  0.572826\n",
       "407-6398      0  0.267134\n",
       "444-7620      1  0.128762\n",
       "352-4885      1  0.593966\n",
       "444-8504      1  0.825960\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['churn', 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWe7LFaIx970"
   },
   "source": [
    "### Q2. Distribution of the churn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the distribution of the predictive scores through a histogram. In this case, we plot separately the scores for the churners (968) and the non-churners (4,032). To do this, we use the module `pyplot` of the library **Matplotlib**. We import it as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sZJ7c2xLyEvc"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see below a code chunk for plotting the two histograms side-by-side. The `plt.figure()` line specifies the total size of the figure. Then, `plt.subplot(1, 2, 1)` and `plt.subplot(1, 2, 2)` start the two parts of this code chunk, one for each subplot. These parts are easy to read after our previous experience with the histogram in example ML-04. The argument `range=(0,1)` is used to get intervals of length 0.1 (the default of ´.hist()´ splits the range of the data in 10 intervals), which are easier to read. The argument `edgecolor=white` improves the picture. \n",
    "\n",
    "Note that `plt.subplot(1, 2, i)` refers to the $i$-th subplot in a grid of one row and two columns. The subplots are ordered by row, from left to righ and from top to bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "VWA3qEmYyG1Z"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the size of the figure\n",
    "plt.figure(figsize=(12,5))\n",
    "# First subplot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['score'][y == 1], range=(0,1), color='gray', edgecolor='white')\n",
    "plt.title('Figure 1.a. Scores (churners)')\n",
    "plt.xlabel('Churn score')\n",
    "# Second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(df['score'][y == 0], range=(0,1), color='gray', edgecolor='white')\n",
    "plt.title('Figure 1.b. Scores (non-churners)')\n",
    "plt.xlabel('Churn score');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now imagine the threshold as a vertical line, and move it, right or left from the default threshold value 0.5. The customers falling on the right of that vertical line would be classified as positive, and those falling on the left as negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRUGhl_PyIzP"
   },
   "source": [
    "### Q3. Set a threshold for the churn scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `.predict()` uses the default threshold 0.5. It is plainly seen in Figure 1.a, that, in this way, we are missing more than one half of the churners. So, in spite of its accuracy, our model would not be adequate for the actual business application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "jxCzxCJFyNDl"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **confusion matrix**, resulting from the cross tabulation of the actual and the predicted target values, confirms this visual intuition. Confusion matrices can be obtained in many ways. For instance, with the function `confusion_matrix` of the scikit-learn subpackage `metrics`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "7bTgWJq7yQ0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3896,  136],\n",
       "       [ 656,  312]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy returned by the method `.score()` is the sum of the diagonal terms of this matrix divided by the sum of all terms of the matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we guessed from the histogram, our churn model is not capturing enough churners (304/968) for a business application. To predict more positives, we have to lower the threshold. Figure 1.a suggests that we have to go down to about 0.2 to make a real difference, while Figure 1.b warns us against lowering it further. So, let us try 0.2. The new vector of predicted clases can then be obtained as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gg6mvS2fyaId"
   },
   "outputs": [],
   "source": [
    "y_pred = (df['score'] > 0.2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new confusion matrix is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "V7MMqdAhycnr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3166,  866],\n",
       "       [ 343,  625]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we are capturing now about 2/3 of the churners. This comes at the price of raising the false positives to 866, which affects the accuracy (now, it is 0.758)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A clear way to summarize the evaluation of the model comes through the true positive and false positive rates. They can be extracted from the confusion matrix or calculated directly. The true positive rate is the proportion of predicted positives among the actual positives (0.646). The false positive rate is the proportion of predicted positives among the actual negatives (0.215)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this data set, there is a mix of scales, twhich can be visualized with the method `.describe()`. This slowns down the convergence in the  method `.fit()`, so we had to increase the parameter `max_iter`. This is not relevant in a model as simple as the one used in this example, but it will be in the complex that will appear later in this course, such the **neural network models**. Try different values for `max_iter` in the specification of the `LogisticRegression()` and examine how the maximum number of iterations affects the model accuracy in this case.\n",
    "\n",
    "2. Rescale all the features which are not dummies and train the logistic regression classifier with the default number of iterations. Do you get a warning about non-convergence now?\n",
    "\n",
    "3. Assume that the Omicron management plans to offer a **20% discount** to the customers that the model classifies as potential churners, and that this offer is going to have a 100% success, so the company will retain all the churners detected. Evaluate the benefit produced by this **retention policy** with the two models presented in this example.\n",
    "\n",
    "4. Write a Python function which gives the benefit in terms of the threshold and find an **optimal threshold** for this retention policy."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSVw47V+iRHUcutocULKgd",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
