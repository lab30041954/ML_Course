{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df4372e-2e21-46d3-9740-b09181e27cd1",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/lab30041954/ML_Course/blob/main/Assignments/Assignment%202%20-%20The%20prof%20solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadaa4a4-58ef-4513-a399-cc37ee3263f6",
   "metadata": {},
   "source": [
    "# Assignment 2 - The prof solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0499c208-2ff8-4932-91f7-e7c4660d8659",
   "metadata": {},
   "source": [
    "### Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a81110-6543-41db-b12e-e1c7fa447b11",
   "metadata": {},
   "source": [
    "Change the features matrix by: (a) dropping the three `cap_` features and (b) **binarizing** all the `word_` features, transforming every column into a dummy for the occurrence of the corresponding word, taking value 1 if the word occurs in the message and 0 otherwise. Based on this new features matrix, train two new spam filters, one based on a logistic regression model and the other one based on a decision tree model, using the binarized data set. Evaluate these new filters and compare them to those obtained before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d43d9a-7c4a-41ee-9913-bf0a034c8cba",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbee785-baab-4475-86dd-96ec77fefb1e",
   "metadata": {},
   "source": [
    "We start by creating the features matrix `X` and the target vector `y`, as usual in supervised learning. The following code chunk has already been used in class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4d15b7b-b294-48f5-bfee-04a50d5ba5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = 'https://raw.githubusercontent.com/lab30041954/Data/main/'\n",
    "df = pd.read_csv(path + 'spam.csv')\n",
    "y = df['spam']\n",
    "X = df.drop(columns='spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f08fb84-8270-44c5-9511-e2e99f55415d",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef6dd5-76fc-43e0-9e2f-efc4b0883225",
   "metadata": {},
   "source": [
    "We create a function for the evaluation of our models on the raw data set, packing the calculations already presented in class. We don't the accuracy, because these data has a spam rate which is not the real one. So we perform separate evaluations on the spam and the legal email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3783fbf2-41c4-4337-abf8-4fe64f772424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def eval1(clf):\n",
    "        y_pred = clf.predict(X)\n",
    "        conf = confusion_matrix(y, y_pred)\n",
    "        tp = conf[1, 1]/sum(conf[1, :])\n",
    "        fp = conf[0, 1]/sum(conf[0, :])\n",
    "        return round(tp, 3), round(fp, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974fd35-ba93-4361-81ee-8f904b8e8e5e",
   "metadata": {},
   "source": [
    "### Logistic regression classifier (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07739f9d-a2a8-40a1-b6d4-3b090b46007b",
   "metadata": {},
   "source": [
    "Firs, we train a logistic regression classifier. Since the data are not normalized, we need to increase the number of iterations to achieve convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a31f0c7-97eb-4d07-8bc3-42d0860ca6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.881), np.float64(0.053))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf1 = LogisticRegression(max_iter=3000)\n",
    "clf1.fit(X, y)\n",
    "eval1(clf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222d870-e067-4e70-95ed-adefc37dd6d3",
   "metadata": {},
   "source": [
    "The true positive rate is quite good (88.1%), while we keep the false negative rate, which is our primary focus, at a moderate level (5.3%)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138e06d0-e4fe-4e7b-9ff8-37e3dd6fd4f6",
   "metadata": {},
   "source": [
    "### Decision tree classifier (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8729630-ece9-434a-9ae1-233c3dbc6d91",
   "metadata": {},
   "source": [
    "Next, we train the last of the decision tree classifiers presented in class. The performance is a bit weaker than that of the logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae844fec-afbc-4eb7-8f66-a7acef216b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.841), np.float64(0.057))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf2 = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "clf2.fit(X, y)\n",
    "eval1(clf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50cc223d-6b91-4e6b-8e9e-ec850ee0dbc3",
   "metadata": {},
   "source": [
    "We take note of the importance ranking, for reference. One of the features that we are going to remove (`cap_ave`) is in the fourth place, which indicates that the removal can affect the performance of the decision tree models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20b55317-3568-466e-9ada-17158683e524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_remove     0.359\n",
       "word_free       0.204\n",
       "word_hp         0.130\n",
       "cap_ave         0.113\n",
       "word_george     0.059\n",
       "word_money      0.045\n",
       "word_edu        0.034\n",
       "cap_long        0.022\n",
       "word_receive    0.013\n",
       "word_your       0.007\n",
       "word_1999       0.004\n",
       "word_650        0.004\n",
       "word_mail       0.003\n",
       "word_hpl        0.002\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp2 = pd.Series(clf2.feature_importances_, index=X.columns)\n",
    "imp2[imp2 > 0].sort_values(ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2891e7b-a38b-4433-bf8e-a22cb94ff56c",
   "metadata": {},
   "source": [
    "### Binary data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98db6d8a-63a2-4343-bd6b-6b8475e452f1",
   "metadata": {},
   "source": [
    "We create the new data set as follows: (a) by picking `X.iloc[:, :-3]` we leave aside the last three columns, (b) with the expression `X.iloc[:, :-3] > 0` we replace the original values by Boolean dummies (`True` when the original value is positive and `False` otherwise), and (c) with `.astype('int')` we convert the Boolean values to ones and zeros. This last conversion is not really needed, and it is included to follow literally the instructions given. We call `BX` the new binary data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1eda46-99da-4134-87d8-75e75f34597a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_make</th>\n",
       "      <th>word_address</th>\n",
       "      <th>word_all</th>\n",
       "      <th>word_3d</th>\n",
       "      <th>word_our</th>\n",
       "      <th>word_over</th>\n",
       "      <th>word_remove</th>\n",
       "      <th>word_internet</th>\n",
       "      <th>word_order</th>\n",
       "      <th>word_mail</th>\n",
       "      <th>...</th>\n",
       "      <th>word_pm</th>\n",
       "      <th>word_direct</th>\n",
       "      <th>word_cs</th>\n",
       "      <th>word_meeting</th>\n",
       "      <th>word_original</th>\n",
       "      <th>word_project</th>\n",
       "      <th>word_re</th>\n",
       "      <th>word_edu</th>\n",
       "      <th>word_table</th>\n",
       "      <th>word_conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_make  word_address  word_all  word_3d  word_our  word_over  \\\n",
       "0          0             1         1        0         1          0   \n",
       "1          1             1         1        0         1          1   \n",
       "2          1             0         1        0         1          1   \n",
       "3          0             0         0        0         1          0   \n",
       "4          0             0         0        0         1          0   \n",
       "\n",
       "   word_remove  word_internet  word_order  word_mail  ...  word_pm  \\\n",
       "0            0              0           0          0  ...        0   \n",
       "1            1              1           0          1  ...        0   \n",
       "2            1              1           1          1  ...        0   \n",
       "3            1              1           1          1  ...        0   \n",
       "4            1              1           1          1  ...        0   \n",
       "\n",
       "   word_direct  word_cs  word_meeting  word_original  word_project  word_re  \\\n",
       "0            0        0             0              0             0        0   \n",
       "1            0        0             0              0             0        0   \n",
       "2            1        0             0              1             0        1   \n",
       "3            0        0             0              0             0        0   \n",
       "4            0        0             0              0             0        0   \n",
       "\n",
       "   word_edu  word_table  word_conference  \n",
       "0         0           0                0  \n",
       "1         0           0                0  \n",
       "2         1           0                0  \n",
       "3         0           0                0  \n",
       "4         0           0                0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BX = (X.iloc[:, :-3] > 0).astype('int')\n",
    "BX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53b6ef2-5018-4ba5-a9e6-f93b82615446",
   "metadata": {},
   "source": [
    "Next, we create a function for the evaluation of our models on the binary data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "546ae063-b882-4496-8e0b-2f1de7693d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval2(clf):\n",
    "        y_pred = clf.predict(BX)\n",
    "        conf = confusion_matrix(y, y_pred)\n",
    "        tp = conf[1, 1]/sum(conf[1, :])\n",
    "        fp = conf[0, 1]/sum(conf[0, :])\n",
    "        return round(tp, 3), round(fp, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189ec116-770b-48c2-b9f4-8570e504be2d",
   "metadata": {},
   "source": [
    "### Logistic regression classifier (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcb3b2d-68c3-46c2-a831-e050813f46fb",
   "metadata": {},
   "source": [
    "We train a logistic regression classifier on the binary data set. We don't need extra iterations now, since all the features are dummies. The performance is about the same as on the original data set, in spite of the information \"lost\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66da7942-c3d4-4514-9497-f7527804c21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.881), np.float64(0.048))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = LogisticRegression()\n",
    "clf3.fit(BX, y)\n",
    "eval2(clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3339d30-c47a-428d-92e6-9d6082ac78f8",
   "metadata": {},
   "source": [
    "### Decision tree classifier (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed5f006-2813-44d7-894d-e2c321c221f0",
   "metadata": {},
   "source": [
    "On the other hand, the performance of the decision tree classifier is a bit weaker on the binary data set. This could be attributed to the removal of one of the relevant features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4306fc1-e016-4191-9905-8bf511758788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.821), np.float64(0.052))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4 = DecisionTreeClassifier(criterion='entropy', max_depth=5)\n",
    "clf4.fit(BX, y)\n",
    "eval2(clf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b27086e-8f40-4778-a521-f76215a5af6a",
   "metadata": {},
   "source": [
    "The new importance ranking does not change in the three top places, and the rest is adapted to new setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d69d9e17-bee2-4b6b-879b-1913ab372cc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "word_remove        0.382\n",
       "word_free          0.206\n",
       "word_hp            0.116\n",
       "word_money         0.102\n",
       "word_internet      0.051\n",
       "word_george        0.051\n",
       "word_edu           0.047\n",
       "word_credit        0.013\n",
       "word_1999          0.007\n",
       "word_your          0.006\n",
       "word_650           0.005\n",
       "word_business      0.003\n",
       "word_labs          0.003\n",
       "word_conference    0.002\n",
       "word_meeting       0.002\n",
       "word_order         0.002\n",
       "word_000           0.001\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imp4 = pd.Series(clf4.feature_importances_, index=BX.columns)\n",
    "imp4[imp4 > 0].sort_values(ascending=False).round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
