{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21275a45-665e-4241-992a-e7c2184da6bf",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lab30041954/ML_IESE_Course/blob/main/%5BML-06%5D%20Neural%20networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a62669-8740-4cf2-9ad1-7b3026ca9717",
   "metadata": {
    "id": "38a62669-8740-4cf2-9ad1-7b3026ca9717"
   },
   "source": [
    "# [ML-06] Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8a58c-4af7-4db5-90be-afea96be21bf",
   "metadata": {
    "id": "92e8a58c-4af7-4db5-90be-afea96be21bf"
   },
   "source": [
    "## What is a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729299d-2e92-40b8-b366-1e2c751606fd",
   "metadata": {
    "id": "5729299d-2e92-40b8-b366-1e2c751606fd"
   },
   "source": [
    "**Neural networks** are as old as artificial intelligence itself, and the expectations about what neural networks could do have experimented up and downs along 60 years. Right now, they are very high. Neural networks and, more specifically, a special type of neural network models, the **transformer**, are taking over machine learning. As more use cases are reported for the new models, expectations about the power of artificial intelligence keep growing.  \n",
    "\n",
    "A neural network can be thought as an interconnected set of computational **nodes** or neurons, organized in **layers**. In the network, every connection of a node to another node has a **weight**. Machine learning happens when these weights are learned from data. The way the nodes are connected in a neural network was initially inspired by ideas about how neurons work together in the brain. Though this is no longer true in most neural network models, in particular in transformers, the discussion about the similarities between the two domains is still alive.\n",
    "\n",
    "There are many types of neural networks. This lecture is restricted to the **multilayer perceptron** (MLP) model, which has been the standard approach for many years. In the next lecture, we will introduce more complex architectures, which we call **deep learning** models.\n",
    "\n",
    "Even if the idea of the neural network as a mathematical model for the brain (which it is not) was attractive, we regard nowadays a neural network as a mathematical function, which takes an input and returns an output. Both the input and the output are **tensors**. A tensor is the same as a NumPy array (though in Python they are different types of objects). So, a 0D tensor is a scalar (a number), a 1D tensor is a vector, a 2D tensor is a matrix, etc. Most of the operations performed with the tensors in a neural network are just linear algebra. We use the package **Keras** in the examples (more detail below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048e217-b3d8-427b-b33a-de483afd9e87",
   "metadata": {
    "id": "7048e217-b3d8-427b-b33a-de483afd9e87"
   },
   "source": [
    "## Basics of the MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4739cf-511c-4b54-933e-e5fd6103294e",
   "metadata": {
    "id": "6e4739cf-511c-4b54-933e-e5fd6103294e"
   },
   "source": [
    "A multilayer perceptron network is formed by:\n",
    "\n",
    "* The **input layer**, whose nodes are the features used for the prediction.\n",
    "\n",
    "* The **output layer**. In regression models, it has a unique node, which is the target (as in the above figure), while, in classification models, it has one node for every target value.\n",
    "\n",
    "* A sequence of **hidden layers**, placed between the input and the output layers. If the network is **fully-connected**, that is, if every node of a layer is connected to all the nodes of the following layer, the **network architecture** is completely specified by the number of hidden layers and the number of nodes in each hidden layer.\n",
    "\n",
    "So the MLP model transforms a 1D tensor of features into either a 0D tensor (regression) or a 1D tensor of class probabilities. These tensors are the input and the output, respectively. How is the transformation performed? Suppose first that $Z$ is a hidden node and $U_1, U_2, \\dots, U_k$ are the nodes of the preceding layer. Then, the values of $Z$ are calculated as\n",
    "\n",
    "$$Z = F\\big(w_0 + w_1U_1 + w_2U_2 + \\cdots + w_kU_k\\big).$$\n",
    "\n",
    "In this context, the slope coefficients $w_1, w_2, \\dots, w_k$  are called weights, and the intercept $w_0$ is called **bias**. $F()$ is the **activation function**.\n",
    "\n",
    "The multilayer perceptron could be seen as if the inout data units were circulating through the network one-by-one. The feature values are entered in the input nodes, which send them to the nodes of the first hidden layer. At each hidden node, they are combined using the corresponding weights, and the result is transformed by means of the activation function. The hidden nodes send the resulting values to the nodes of the next layer, where they are combined. And so on, until arriving to the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492258f-5640-455b-9a1f-216bc03d99ec",
   "metadata": {
    "id": "a492258f-5640-455b-9a1f-216bc03d99ec"
   },
   "source": [
    "## A graphical example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c25c58b-da19-4061-aa91-c115245a7ac8",
   "metadata": {
    "id": "2c25c58b-da19-4061-aa91-c115245a7ac8"
   },
   "source": [
    "Let us help our intuition with the graphical representation of a small network. The model of the figure below is an MLP regressor with one hidden layer of two nodes. The diagram is just a graphical representation of a set of three equations, two for the hidden nodes and one for the output node. The equation of node $A$ combines $X_1$, $X_2$ and $X_3$ with weights $w_{1A}$, $w_{2A}$ and $w_{3A}$, while the equation in node $B$ combines them with weights $w_{1B}$, $w_{2B}$ and $w_{3B}$. The biases are $w_{0A}$ and $w_{0B}$, respectively.\n",
    "\n",
    "![](https://raw.githubusercontent.com/lab30041954/Figures/main/nn.png)\n",
    "\n",
    "At the hidden nodes, the **activation function** is applied to the values given by these equations. Once the activation has been applied, the outcomes of the two hidden nodes are combined in the third equation, with weights $w_{AY}$ and $w_{BY}$ and bias $w_{0Y}$, to obtain the predicted value of $Y$. This model has a total of 11 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5218790-5d5d-4c01-b2c3-df2fb828f58c",
   "metadata": {
    "id": "d5218790-5d5d-4c01-b2c3-df2fb828f58c"
   },
   "source": [
    "## The activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ceca8-b763-45bd-a59c-2a7feade770c",
   "metadata": {
    "id": "627ceca8-b763-45bd-a59c-2a7feade770c"
   },
   "source": [
    "The choice of the activation function is based on performance, since we do not have any serious theory that could explain why a specific mathematical formula works better than others. For the activation in the hidden nodes, the current trend favors the **rectified linear unit function** ($\\hbox{ReLU}$). $\\hbox{ReLU}(x)$ is equal to $x$ when $x>0$ and equal to $0$ otherwise. So, the default activation in the hidden layers consists in turning the negative incoming values into zeros.\n",
    "\n",
    "In a MLP regressor (as in the figure), there is no activation at the (single) output node, so the equation predicting the values at that node is linear. In a MLP classifier, there are as many output nodes as target values. A **softmax activation** is applied to the whole set of incoming values, turning them into a set of **class probabilities**. In mathematical terms, this is the same as logistic regression applied to the output of the last hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975ec9e-ed2c-4e86-b0bf-5f4fa063b633",
   "metadata": {
    "id": "1975ec9e-ed2c-4e86-b0bf-5f4fa063b633"
   },
   "source": [
    "## Other technicalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3407e7f-dd91-4f88-9e7b-58fc7258f8b4",
   "metadata": {
    "id": "f3407e7f-dd91-4f88-9e7b-58fc7258f8b4"
   },
   "source": [
    "* *How to find the optimal weights*. Initially, the weights are randomly assigned. Then, an iterative process starts. At every step, the prediction is performed with the current weights, the value of a **loss function** is calculated, and the weights are adjusted in order to reduce the loss. The process is expected to converge to an optimal solution, but, in practice, a maximum number of passes is pre-specified. In regression, the loss is usually the MSE, while, in classification, it is the average cross-entropy (Keras uses natural logs to calculate it). The adjustment of the weights starts at the last layer, and continues backwards until the input layer. This is called **backpropagation**.\n",
    "\n",
    "* *The optimization method*, called **solver** in scikit-learn and **optimizer** in the Keras API. The current trend favors the **stochastic gradient descent** (SGD) method, which has many variants. Though you may find in books or tutorials the variant `optimizer='rmsprop'`, we use here `optimizer='adam'`, which is faster.\n",
    "\n",
    "* *The number of iterations*, that is, the number of times every data unit passes through the network, is controlled in Keras with the parameter **epochs**. The default is `epochs=1`. In SGD, the units don't pass all at once, but in **random batches** (see below).\n",
    "\n",
    "* *The batch size*. In the SGD method, the training data are randomly partitioned in batches in every iteration. The batches are tried one-by-one and the weights are modified every time that a batch is tried. The Keras default is `batch_size=32`. We don't change this in the examples of this course.\n",
    "\n",
    "* *The learning rate*, which we have already found in gradient boosting models, is a parameter which rules how fast the adjustment of the weights is done. If it is too low, there is no convergence to the optimal solution. If it is too high, you can overshoot the optimal solution. Modern ML software allows setting an initial learning rate and decrease it as the learning process goes on. The Keras default is `learning_rate=0.001`.\n",
    "\n",
    "* *Normalization*. Optimization methods are sensitive to feature scaling, so it is highly recommended to scale your data. The example of this lecture illustrates this point in very clear way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b4a1e-b1e2-4654-afdd-c50029b8706b",
   "metadata": {
    "id": "1f6b4a1e-b1e2-4654-afdd-c50029b8706b"
   },
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f711c-f520-492d-8c43-52d517646da6",
   "metadata": {
    "id": "8c5f711c-f520-492d-8c43-52d517646da6"
   },
   "source": [
    "**Keras** is a deep learning framework for Python (there is also a version for R), which provides a convenient way to define and train neural network models. The documentation is available at `https://keras.io`. Keras does not handle itself low-level operations such as tensor manipulation and differentiation. Instead, it relies on a specialized tensor library to do so. That library serves as the **backend** engine of Keras.\n",
    "\n",
    "Keras was organized in a modular way, so several different backend engines could be plugged seamlessly into Keras. The default backend is \n",
    "the library **TensorFlow**, developed at Google Brain and released in 2015, which has been for years the top popular choice. The dominance of TensorFlow seems to be over, and Google is no longer updating it, so there is not a version of TensorFlow for Python 3.13. If you are working in Google Colab, you don't have to worry about this. You can import the Keras functions that you need without any preliminary step. \n",
    "\n",
    "If you are working with a local Python installation, the options are:\n",
    "\n",
    "* If you have Python 3.12 or older, you can use the default, or any of the two alternatives listed below. You can install the resources needed with\n",
    "\n",
    "```\n",
    "! pip install keras tensorflow\n",
    "```\n",
    "\n",
    "* If have Python 3.13 or later, you can choose between **JAX**, supported by Google, or **PyTorch** (time ago supported by Meta), which is very popular in the LLM area. This notebook uses JAX, which is faster. The installation step is then:\n",
    "\n",
    "```\n",
    "! pip install keras jax\n",
    "```\n",
    "\n",
    "If you don't use the default backend, you have to specify that before importing the Keras functions. For JAX, you can do it with:\n",
    "\n",
    "```\n",
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'\n",
    "```\n",
    "\n",
    "If you prefer PyTorch, replace `jax` by `torch`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7d43a-fa55-4ca6-ba17-5141fc293413",
   "metadata": {
    "id": "b3b7d43a-fa55-4ca6-ba17-5141fc293413"
   },
   "source": [
    "## Example - The MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7541389-25ba-4302-85e2-1b1d73073785",
   "metadata": {
    "id": "f7541389-25ba-4302-85e2-1b1d73073785"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737b3a7-6622-45db-908f-ef9e64092901",
   "metadata": {
    "id": "9737b3a7-6622-45db-908f-ef9e64092901"
   },
   "source": [
    "This example deals with the classification of grayscale images of handwritten digits (resolution 28 $\\times$ 28), into 10 classes (0 to 9). The data are the famous **MNIST data**, a classic in the ML community, which have been around for almost as long as the field itself, and have been very intensively studied.\n",
    "\n",
    "The MNIST data set contains 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (NIST) in the 1980s. They have been extensively used for benchmarking. You can think of \"solving\" MNIST as the \"Hello World\" of deep learning. As you become an ML practitioner, the MNIST data come up over and over again, in scientific papers, blog posts, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680ab7b-db99-45f2-8db7-98a0b0cbfedd",
   "metadata": {
    "id": "8680ab7b-db99-45f2-8db7-98a0b0cbfedd"
   },
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15b246-f095-4aed-9c24-224c26297a24",
   "metadata": {
    "id": "fc15b246-f095-4aed-9c24-224c26297a24"
   },
   "source": [
    "The data of the 70,000 images come together in the file `mnist.csv` (zipped). Every row stands for an image. The first column is a label identifying the digit (0-9). The other 784 columns correspond to the image pixels (28 $\\times$ 28 = 784). The column name `ixj` must be read as the gray intensity of the pixel in row $i$ and column $j$ (in the images). These intensities are integers from 0 = Black to 255 = White (8-bit grayscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e56555-b023-456c-8d4f-f2b6ab6a7b5d",
   "metadata": {
    "id": "27e56555-b023-456c-8d4f-f2b6ab6a7b5d"
   },
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d412391-059e-4e64-b6d1-5d4502fc9939",
   "metadata": {
    "id": "6d412391-059e-4e64-b6d1-5d4502fc9939"
   },
   "source": [
    "Q1. Pick the first digit image (row 1). The 784 entries on the right of the label, from `1x1` to `28x28`, are the pixels' gray intensities. Pack these numbers as a vector and reshape that vector as a matrix of 28 rows and 28 columns. Plot the corresponding image with the `matplotlib.pyplot` function `imshow()`. This function will be using default colors which do not help here, so you can turn everything into gray scale by executing the function `gray()`. Your plot will have then black background, with the number drawn in white. Guess how to reverse this, so the image looks like white paper with a number drawn in black ink.\n",
    "\n",
    "Q2. Repeat the exercise with other images. You don't need the function `gray()` anymore.\n",
    "\n",
    "Q3. Split the data in a training set with 60,000 data units and a test set with 10,000 units.\n",
    "\n",
    "Q4. Train and test a **decision tree classifier** and a **random forest classifier** on these data, controlling the growth of the trees with the argument `max_leaf_nodes=128`.\n",
    "\n",
    "Q5. Train and test a MLP model, with a hidden layer of 32 nodes, using that split.\n",
    "\n",
    "Q6. How does the MLP model make predictions?\n",
    "\n",
    "Q7. Convert the gray scale to the 0-1 range (0 = Black, 1 = White), and try again with the same MLP architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb953da4-3352-49fb-a42e-86b0600bc61a",
   "metadata": {
    "id": "cb953da4-3352-49fb-a42e-86b0600bc61a"
   },
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65414bb-8447-42c0-85cc-34553b0209f8",
   "metadata": {
    "id": "e65414bb-8447-42c0-85cc-34553b0209f8"
   },
   "source": [
    "We use the Pandas function `read_csv()` to import the data from our GitHub repository. Since the images do not have an identifier, we leave Pandas to create a `RangeIndex`. The source file is zipped, but `read_csv()` can manage this without a specific argument, based on the file extension `.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0681e1-e301-49a5-8d27-f18c58e97adc",
   "metadata": {
    "id": "fa0681e1-e301-49a5-8d27-f18c58e97adc"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "path = 'https://raw.githubusercontent.com/lab30041954/Data/main/'\n",
    "df = pd.read_csv(path + 'mnist.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdc772-8a2c-4729-88d7-4c4fc7e5dc1b",
   "metadata": {
    "id": "07fdc772-8a2c-4729-88d7-4c4fc7e5dc1b"
   },
   "source": [
    "We check the shape of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfb26ba-b302-4600-9c2e-a20ec2ac000f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdfb26ba-b302-4600-9c2e-a20ec2ac000f",
    "outputId": "106fe09b-50d3-4e1b-bc83-ee3679cdb92b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730d4ef-e5f3-4b27-abb4-e90d012d6b50",
   "metadata": {
    "id": "2730d4ef-e5f3-4b27-abb4-e90d012d6b50"
   },
   "source": [
    "### Target vector and features matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb488669-bba3-43fe-8680-76da5a7ac1b4",
   "metadata": {
    "id": "fb488669-bba3-43fe-8680-76da5a7ac1b4"
   },
   "source": [
    "We set the first column (the image labels) as the target vector and the pixel intensities as the features matrix. We use only NumPy arrays in this example, to simplify the syntax. So, we convert the Pandas objects retruned by `read_csv()` to arrays, by adding `.values` at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897e5038-cc82-49e1-9e10-a68de4dd7987",
   "metadata": {
    "id": "897e5038-cc82-49e1-9e10-a68de4dd7987"
   },
   "outputs": [],
   "source": [
    "y = df['label'].values\n",
    "X = df.drop(columns='label').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd6652-75ea-4ad0-bd99-0ba18127a72c",
   "metadata": {
    "id": "32bd6652-75ea-4ad0-bd99-0ba18127a72c"
   },
   "source": [
    "We can examine the labels the NumPy function `unique()`. This shows that the data are a bit unbalanced: ones are most frequent, and fives least frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91b9aca-293b-4063-82b3-f664cd4c46f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b91b9aca-293b-4063-82b3-f664cd4c46f9",
    "outputId": "56f0e0e6-29b8-4e59-c7dc-73e6e5e92844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([6903, 7877, 6990, 7141, 6824, 6313, 6876, 7293, 6825, 6958]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539bbe6-a5f6-4f49-a6a4-b5bfc1414459",
   "metadata": {
    "id": "8539bbe6-a5f6-4f49-a6a4-b5bfc1414459"
   },
   "source": [
    "The pixel values can also be checked with `unique()`. We don't calculate here the counts for the 256 values, to keep it short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f87673f-39e1-4088-8f89-70c2cbc985d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f87673f-39e1-4088-8f89-70c2cbc985d1",
    "outputId": "a2f35273-3c81-4847-d423-c432c3101585"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a8324-896d-4824-bcef-87ddc962ec0e",
   "metadata": {
    "id": "bf3a8324-896d-4824-bcef-87ddc962ec0e"
   },
   "source": [
    "### Q1. Plotting the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160bb09-731b-4b46-b64e-493eeaa0fa66",
   "metadata": {
    "id": "5160bb09-731b-4b46-b64e-493eeaa0fa66"
   },
   "source": [
    "Each row corresponds to the image of one digit. Let us visualize this by plotting the images with Matplotlib. As the data come, we have in the first row of the data set the pixels' gray intensities, from 1 $\\times$ 1 to 28 $\\times$ 28$, extracted row-by-row from the original pixel matrix. To plot the image, we have to reshape it as a 2D array with 28 rows and 28 columns. This can be done with the method `.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbec20db-4cc7-472a-9282-8acf6a7fb430",
   "metadata": {
    "id": "bbec20db-4cc7-472a-9282-8acf6a7fb430"
   },
   "outputs": [],
   "source": [
    "pic = X[0, :].reshape(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1199d120-1058-4e4b-96f8-2aed7e27b4e3",
   "metadata": {
    "id": "1199d120-1058-4e4b-96f8-2aed7e27b4e3"
   },
   "source": [
    "The `matplotlib.pyplot` function `imshow()` converts this array to an image and displays it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86984516-f037-4cee-991a-15e6f5fd5bd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "86984516-f037-4cee-991a-15e6f5fd5bd1",
    "outputId": "40153455-0f10-4405-d128-65f349515f34"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4dfea-3235-417a-8e76-e1b86582f4b5",
   "metadata": {
    "id": "fcd4dfea-3235-417a-8e76-e1b86582f4b5"
   },
   "source": [
    "These are the default colors displayed by `imshow()`. To turn them into gray scale, one can use the argument `cmap='gray'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c92b75-40c5-4e88-b8c5-87dc0c6fa60a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "b4c92b75-40c5-4e88-b8c5-87dc0c6fa60a",
    "outputId": "c6d1ee2b-349f-469e-d132-169529e1da5a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pic, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18002e1-55b7-4322-be4b-5f5d8c2bf7bf",
   "metadata": {
    "id": "d18002e1-55b7-4322-be4b-5f5d8c2bf7bf"
   },
   "source": [
    "The gray scale can be set as the default by mean of the function `gray()`. Now, reversing the scale, we can display the image as it were a digit written with black pencil on a white paper surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e10cce1-54c1-4897-b99b-48283de5d709",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "6e10cce1-54c1-4897-b99b-48283de5d709",
    "outputId": "6452c673-52e8-4300-fa13-fc9c63bc142e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.imshow(255 - pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824a8d1-95ce-4578-adca-9e609057a69b",
   "metadata": {
    "id": "0824a8d1-95ce-4578-adca-9e609057a69b"
   },
   "source": [
    "This five is far from caligraphic, but still recognizable by a human eye."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06fd214-959e-4050-90dc-398c482c460e",
   "metadata": {
    "id": "b06fd214-959e-4050-90dc-398c482c460e"
   },
   "source": [
    "### Q2. Plotting other images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3db2d2-98d1-4cab-8eec-4c21f256c781",
   "metadata": {
    "id": "5e3db2d2-98d1-4cab-8eec-4c21f256c781"
   },
   "source": [
    "The second image of the data set is a zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91c9487-d8f9-4faa-bed9-49e878c1c7cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "e91c9487-d8f9-4faa-bed9-49e878c1c7cb",
    "outputId": "8b09d7c0-2bb5-4d0a-c38f-4a0200b737b2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pic = X[1, :].reshape(28,28)\n",
    "plt.imshow(255 - pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4458ca35-03be-4ba4-a5ce-d124fea86d5c",
   "metadata": {
    "id": "4458ca35-03be-4ba4-a5ce-d124fea86d5c"
   },
   "source": [
    "And the third one a four:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47637827-a3f6-433c-9bb4-f34b1b8df959",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "47637827-a3f6-433c-9bb4-f34b1b8df959",
    "outputId": "db239221-0426-4c88-d4be-26eab56133a9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pic = X[2, :].reshape(28,28)\n",
    "plt.imshow(255 - pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa0c9b-0ae2-4277-bef0-db6f3756a212",
   "metadata": {
    "id": "3cfa0c9b-0ae2-4277-bef0-db6f3756a212"
   },
   "source": [
    "### Q3. Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc0a1a-aff4-44ec-98bc-3d8e3472a80b",
   "metadata": {
    "id": "99dc0a1a-aff4-44ec-98bc-3d8e3472a80b"
   },
   "source": [
    "We split the data set, so we can validate the models that we will train. We keep 10,000 pictures for testing, which is common practice with the MNIST data. We set `random_state=0` for reproducibility. So, we will be able to rescale the features and apply the same split to the rescaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35bbb944-be3f-46f4-85d5-b20916c95a40",
   "metadata": {
    "id": "35bbb944-be3f-46f4-85d5-b20916c95a40"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234f78d-ba8d-456a-84ab-1d3197fb53fc",
   "metadata": {
    "id": "d234f78d-ba8d-456a-84ab-1d3197fb53fc"
   },
   "source": [
    "### Q4. Tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1e72c-d7a3-45ba-900e-09e03b41ab00",
   "metadata": {
    "id": "17d1e72c-d7a3-45ba-900e-09e03b41ab00"
   },
   "source": [
    "We start with a decision tree classifier, to get a first benchmark. We use an estimator from the class `DecisionTreeClassifier()`, of the scikit-learn subpackage `tree`. Given the size of the data set, we set `max_leaf_nodes=128`, to control the growth of the tree. We calculate the accuracy on both training and test data. The accuracy can be a good way to evaluate this model, since the data set is quite balanced and we don't have any preference for a particular digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9cbc91-e532-4866-b353-5a39c7e1299d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a9cbc91-e532-4866-b353-5a39c7e1299d",
    "outputId": "f4ee3a61-eec0-464d-c150-84654307c087"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.809, 0.791)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_leaf_nodes=128)\n",
    "treeclf.fit(X_train, y_train)\n",
    "round(treeclf.score(X_train, y_train), 3), round(treeclf.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e2958-ba97-4cc7-9063-d26bcde75a79",
   "metadata": {
    "id": "043e2958-ba97-4cc7-9063-d26bcde75a79"
   },
   "source": [
    "Even if the tree is big, we don't find evidence of overfitting. The accuracy is not negligeable, but would not be enough for business applications. For instance, to be used on scanned zipcodes (five digits). Maintaining the specification for the tree size, we try now a random forest classifier with 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b772cf7b-287a-4f11-968f-386ef4dec2fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b772cf7b-287a-4f11-968f-386ef4dec2fd",
    "outputId": "edcc1043-d3d0-4e65-bcda-61f6c6395e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.925, 0.915)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_leaf_nodes=128, n_estimators=100)\n",
    "rfclf.fit(X_train, y_train)\n",
    "round(rfclf.score(X_train, y_train), 3), round(rfclf.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4c99d-cbce-467b-a20c-2a0a985b4318",
   "metadata": {
    "id": "5ca4c99d-cbce-467b-a20c-2a0a985b4318"
   },
   "source": [
    "This is clearly better than an individual tree, and overfitting is moderate. The homework suggests that you can improve this a bit more by changing the specs. You can also try a gradient boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736f569-9e29-495d-8314-d16148507d08",
   "metadata": {
    "id": "4736f569-9e29-495d-8314-d16148507d08"
   },
   "source": [
    "### Q5. MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e1d03d-bdcb-4201-bbcd-190d3a5af76a",
   "metadata": {
    "id": "62e1d03d-bdcb-4201-bbcd-190d3a5af76a"
   },
   "source": [
    "We try now a simple neural network, using the Keras, with the JAX backend. Assuming that Keras and JAX are already installed, we start by specifying the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a0b8da6-9292-4d44-933e-06899d8601d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'jax'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000c5f0-8be1-4e40-8a08-186c61c1293c",
   "metadata": {},
   "source": [
    "From Keras, we take the function `Input()` and the modules `models` and `layers`, which contain the resources needed for this example. Don't pay attention to the warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec5efbda-feec-495a-a657-00a347b3bca3",
   "metadata": {
    "id": "ec5efbda-feec-495a-a657-00a347b3bca3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "from keras import Input, models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d750f-5f22-4293-9444-22fba2d41211",
   "metadata": {
    "id": "2c0d750f-5f22-4293-9444-22fba2d41211"
   },
   "source": [
    "The module `models` has two classes, `.Sequential()` and `.Model()`. The first one can only specify a network architecture made of a sequence of layers. The second one, known as the **Functional API**, does not have that restriction. We use `.Model()` in this course.\n",
    "\n",
    "A simple way to specify the network architecture is to create a list of layers. The layers are extracted from classes of the module `layers`. For an MLP network we only need the class `Dense()`. For instance, a MLP network with one hidden layer of 32 nodes for the MNIST data would be specified as follows. First, the **input layer** contains one node for every feature (there 784 features, one for each pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09be2ff-d5f8-4ce4-af7b-3f772a31f96e",
   "metadata": {
    "id": "c09be2ff-d5f8-4ce4-af7b-3f772a31f96e"
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee86f730-cca8-4f88-9977-7cff0158148b",
   "metadata": {
    "id": "ee86f730-cca8-4f88-9977-7cff0158148b"
   },
   "source": [
    "Next, the **hidden layer**, that transforms the input tensor (length 784) into a new tensor (length (32). It is a dense layer, meaning that every node is connected to all nodes of the preceding layer. The activation function is the **rectified linear unit function** (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "563a762b-6aa5-4b8c-8073-3455dbea9c0b",
   "metadata": {
    "id": "563a762b-6aa5-4b8c-8073-3455dbea9c0b"
   },
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation='relu')(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed95aa-88c8-4841-b697-de029802dc0b",
   "metadata": {
    "id": "a8ed95aa-88c8-4841-b697-de029802dc0b"
   },
   "source": [
    "Finally, the **output layer** transforms the hidden tensor (length 32) into a tensor of class probabilities (length 10). The activation function is here the **softmax**, which ensures that the output is a vector of probabilities (positive numbers summing 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0cff7193-3581-4b0e-99ba-22890f731690",
   "metadata": {
    "id": "0cff7193-3581-4b0e-99ba-22890f731690"
   },
   "outputs": [],
   "source": [
    "output_tensor = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f907eb-6b3c-4d29-8d5c-c8e2c106b3c8",
   "metadata": {
    "id": "08f907eb-6b3c-4d29-8d5c-c8e2c106b3c8"
   },
   "source": [
    "The next step is to instantiate an object of the class `models.Model()`. This works as in scikit-learn. We specify here the input and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "26e3fa44-c5bc-4a16-b5bf-28cecaa7ddae",
   "metadata": {
    "id": "26e3fa44-c5bc-4a16-b5bf-28cecaa7ddae"
   },
   "outputs": [],
   "source": [
    "mlpclf1 = models.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e158336-b981-4e3c-bf8a-34c84e0067dd",
   "metadata": {
    "id": "8e158336-b981-4e3c-bf8a-34c84e0067dd"
   },
   "source": [
    "The method `.summary()` prints a summary of the network architecture, reporting the number of parameters in every layer. In the hidden layer, every node receives 784 inputs (one for each pixel), which are combined wby means of a linear expression involving the same number of **weights** (the slope coefficients) plus a **bias** (the intercept). So, 785 parameters are needed at every node, which makes a total of 32 $\\times$ 785 = 25,120 parameters. In a similar way, in the output layer, every node needs 33 parameters, which adds 10 $\\times$ 33 = 330 parameters to get a total of 25,450 parameters for the whole network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec50f670-643a-4978-a705-11a85e491b7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "ec50f670-643a-4978-a705-11a85e491b7e",
    "outputId": "30928f52-fd13-4133-f769-8cffcfb452e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                         <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> \n",
       "\n",
       " dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                    (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> \n",
       "\n",
       " dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " input_layer (\u001b[38;5;33mInputLayer\u001b[0m)         (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                         \u001b[38;5;34m0\u001b[0m \n",
       "\n",
       " dense (\u001b[38;5;33mDense\u001b[0m)                    (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                     \u001b[38;5;34m25,120\u001b[0m \n",
       "\n",
       " dense_1 (\u001b[38;5;33mDense\u001b[0m)                  (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                        \u001b[38;5;34m330\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,450</span> (99.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,450\u001b[0m (99.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,450</span> (99.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,450\u001b[0m (99.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlpclf1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f24051-cb52-4643-9c8f-e79edbe28ad9",
   "metadata": {
    "id": "69f24051-cb52-4643-9c8f-e79edbe28ad9"
   },
   "source": [
    "Now, we **compile** the mathematical apparatus needed for the learning process gets ready. We have to specify the **optimization algorithm** (`optimizer='adam'`), the **loss function** (`loss='sparse_categorical_crossentropy'`) and the metrics used to evaluate the model performance (`metrics=['acc']`), in a list or dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1d0f2c5-bb04-49a7-bfb2-248b7d8aa2ad",
   "metadata": {
    "id": "b1d0f2c5-bb04-49a7-bfb2-248b7d8aa2ad"
   },
   "outputs": [],
   "source": [
    "mlpclf1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc88510-1993-4082-8008-36b719faee3e",
   "metadata": {
    "id": "8fc88510-1993-4082-8008-36b719faee3e"
   },
   "source": [
    "We are ready now to apply the method `.fit()`. Note that the number of iterations is specified here, not when creating the model, as it was in scikit-learn. In every iteration, or **epoch**, the data set is randomly split in batches of size 32 (if you accept the deafult size). These batches are passed sequentially, and the parameter values are updated for every batch. This means that they not are updated 50 times, but 50 times the number of batches (1,875). By default, a report of the progress is gradually displayed on the screen. In this example, every epoch takes about nine seconds in a regular laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90b9d62b-e0b9-4a00-aa10-996b73a7e748",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90b9d62b-e0b9-4a00-aa10-996b73a7e748",
    "outputId": "cab51e20-dec5-475f-a35f-23864a61c32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 497us/step - acc: 0.4240 - loss: 9.2329 - val_acc: 0.4693 - val_loss: 8.5246\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314us/step - acc: 0.5981 - loss: 6.4347 - val_acc: 0.6522 - val_loss: 5.5685\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337us/step - acc: 0.6467 - loss: 5.6616 - val_acc: 0.6489 - val_loss: 5.6280\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 335us/step - acc: 0.6543 - loss: 5.5472 - val_acc: 0.6611 - val_loss: 5.4338\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316us/step - acc: 0.6564 - loss: 5.5177 - val_acc: 0.6620 - val_loss: 5.4261\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step - acc: 0.6592 - loss: 5.4756 - val_acc: 0.6457 - val_loss: 5.6866\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - acc: 0.6639 - loss: 5.4016 - val_acc: 0.6701 - val_loss: 5.2975\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - acc: 0.6635 - loss: 5.4079 - val_acc: 0.6594 - val_loss: 5.4791\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 302us/step - acc: 0.6669 - loss: 5.3542 - val_acc: 0.6712 - val_loss: 5.2836\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317us/step - acc: 0.6653 - loss: 5.3836 - val_acc: 0.6587 - val_loss: 5.4862\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 322us/step - acc: 0.6645 - loss: 5.3958 - val_acc: 0.6506 - val_loss: 5.6113\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - acc: 0.6678 - loss: 5.3443 - val_acc: 0.6660 - val_loss: 5.3742\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 332us/step - acc: 0.6669 - loss: 5.3597 - val_acc: 0.6658 - val_loss: 5.3766\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328us/step - acc: 0.6673 - loss: 5.3537 - val_acc: 0.6716 - val_loss: 5.2802\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314us/step - acc: 0.6704 - loss: 5.3018 - val_acc: 0.6664 - val_loss: 5.3695\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327us/step - acc: 0.6678 - loss: 5.3449 - val_acc: 0.6658 - val_loss: 5.3733\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314us/step - acc: 0.6712 - loss: 5.2916 - val_acc: 0.6698 - val_loss: 5.3181\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316us/step - acc: 0.6693 - loss: 5.3215 - val_acc: 0.6686 - val_loss: 5.3289\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 328us/step - acc: 0.6705 - loss: 5.3056 - val_acc: 0.6741 - val_loss: 5.2419\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334us/step - acc: 0.6717 - loss: 5.2828 - val_acc: 0.6731 - val_loss: 5.2641\n"
     ]
    }
   ],
   "source": [
    "mlpclf1.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "goQg5XU8zCqr",
   "metadata": {
    "id": "goQg5XU8zCqr"
   },
   "source": [
    "This is encouraging so far. We will see below how to improve the performance of the model by rescaling the features, as suggested in question Q7. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09271694-ad40-4d85-a2ce-616273cb6e8b",
   "metadata": {},
   "source": [
    "*Note*. The performance of a neural network model trained with non-normalized data (something you should not do) varies across tensor libraries. So, you can get better results here with TensorFlow or PyTorch. These differences disappear one you normalize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e4392-c9dd-4817-b13b-0e3532533de8",
   "metadata": {
    "id": "932e4392-c9dd-4817-b13b-0e3532533de8"
   },
   "source": [
    "### Q6. Prediction with a MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77419e4f-4cb1-4a94-977e-85c973ed83f1",
   "metadata": {
    "id": "77419e4f-4cb1-4a94-977e-85c973ed83f1"
   },
   "source": [
    "In a classification setting, the Keras method `.predict()` returns the class probabilities (not the predicted class), just as the scikit-learn method `.predict_proba()`. In this example, it returns, for a given input, the 10 values given by the softmax activation at the output nodes, which are the **predicted class probabilities** for that input. For instance, for the first digit of the test set, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d909f5f-72cc-459e-9791-80b75e1ec62e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d909f5f-72cc-459e-9791-80b75e1ec62e",
    "outputId": "ebf10cd4-81dd-43f1-e750-e1da1cd23ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.000000e+00, 0.000000e+00, 0.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 4.650172e-21, 1.000000e+00, 0.000000e+00,\n",
       "        0.000000e+00, 0.000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf1.predict(X_test[:1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h1fMOc750_1h",
   "metadata": {
    "id": "h1fMOc750_1h"
   },
   "source": [
    "According to the model, with probability 1, this is a six. So this is one among the prediction is not correct (almost 23% of the predictions are wrong):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "IsciAc_21Hm8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsciAc_21Hm8",
    "outputId": "8121b226-addb-4cf6-bb17-be4130fbbbe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d1d39-dba6-43cd-8f31-e5db5bfb607c",
   "metadata": {
    "id": "086d1d39-dba6-43cd-8f31-e5db5bfb607c"
   },
   "source": [
    "### Q7. Rescaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d7fc6-5d5c-47b6-8f76-2d8c458ee65d",
   "metadata": {
    "id": "bb5d7fc6-5d5c-47b6-8f76-2d8c458ee65d"
   },
   "source": [
    "As a general rule, it is recommended to rescale the features to the 0-1 range. This speeds up the convergence and may improve the predictions. In this example, we can rescale the pixel intensities by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8ff0601-1827-4632-8e88-723fe6ebda59",
   "metadata": {
    "id": "a8ff0601-1827-4632-8e88-723fe6ebda59"
   },
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46842bb6-40c8-41fc-be8b-7bf33de7aa9d",
   "metadata": {
    "id": "46842bb6-40c8-41fc-be8b-7bf33de7aa9d"
   },
   "source": [
    "We have now a new features matrix, that we split exactly in the same way as we did with before (the argument `random_state=0` does the trick)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bb87767-2a0b-4aaa-80b7-6ba0e9d15382",
   "metadata": {
    "id": "7bb87767-2a0b-4aaa-80b7-6ba0e9d15382"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=1/7, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec606b-2c5d-4c55-a9c9-2958378f7308",
   "metadata": {
    "id": "ddec606b-2c5d-4c55-a9c9-2958378f7308"
   },
   "source": [
    "Now, we instantiate a new model, which we train on the rescaled data. We keep `epochs=20`, even if we guess that so many epochs are not needed. The training process is faster (five epochs are enough), and the results are significantly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "22c400ed-01b3-4bd1-a25a-f46713c0e824",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22c400ed-01b3-4bd1-a25a-f46713c0e824",
    "outputId": "21904665-d275-41ea-c82b-0b74270ad96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 413us/step - acc: 0.9133 - loss: 0.3296 - val_acc: 0.9437 - val_loss: 0.1927\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - acc: 0.9564 - loss: 0.1522 - val_acc: 0.9515 - val_loss: 0.1581\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - acc: 0.9644 - loss: 0.1256 - val_acc: 0.9561 - val_loss: 0.1428\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 354us/step - acc: 0.9676 - loss: 0.1094 - val_acc: 0.9601 - val_loss: 0.1336\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 314us/step - acc: 0.9712 - loss: 0.0978 - val_acc: 0.9633 - val_loss: 0.1273\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 311us/step - acc: 0.9733 - loss: 0.0891 - val_acc: 0.9630 - val_loss: 0.1222\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309us/step - acc: 0.9758 - loss: 0.0818 - val_acc: 0.9640 - val_loss: 0.1235\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310us/step - acc: 0.9768 - loss: 0.0761 - val_acc: 0.9651 - val_loss: 0.1190\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 312us/step - acc: 0.9785 - loss: 0.0708 - val_acc: 0.9651 - val_loss: 0.1212\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - acc: 0.9801 - loss: 0.0663 - val_acc: 0.9654 - val_loss: 0.1221\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313us/step - acc: 0.9812 - loss: 0.0617 - val_acc: 0.9649 - val_loss: 0.1246\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - acc: 0.9822 - loss: 0.0584 - val_acc: 0.9657 - val_loss: 0.1209\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 313us/step - acc: 0.9834 - loss: 0.0552 - val_acc: 0.9680 - val_loss: 0.1192\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 310us/step - acc: 0.9842 - loss: 0.0516 - val_acc: 0.9660 - val_loss: 0.1250\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - acc: 0.9854 - loss: 0.0484 - val_acc: 0.9651 - val_loss: 0.1239\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - acc: 0.9857 - loss: 0.0461 - val_acc: 0.9672 - val_loss: 0.1219\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317us/step - acc: 0.9870 - loss: 0.0438 - val_acc: 0.9657 - val_loss: 0.1268\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step - acc: 0.9872 - loss: 0.0413 - val_acc: 0.9669 - val_loss: 0.1251\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 320us/step - acc: 0.9884 - loss: 0.0386 - val_acc: 0.9666 - val_loss: 0.1300\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315us/step - acc: 0.9891 - loss: 0.0372 - val_acc: 0.9660 - val_loss: 0.1331\n"
     ]
    }
   ],
   "source": [
    "mlpclf2 = models.Model(input_tensor, output_tensor)\n",
    "mlpclf2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "mlpclf2.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6fe465-675e-4820-b8a0-3dce6ad26aaa",
   "metadata": {},
   "source": [
    "We will continue working on these data, using a more complex network architecture. Meanwhile, you can play around using the questions listed below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wSMQIbnL2enZ",
   "metadata": {
    "id": "wSMQIbnL2enZ"
   },
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KhpHMwIN29Ka",
   "metadata": {
    "id": "KhpHMwIN29Ka"
   },
   "source": [
    "1. At every node of every tree, the **random forest** algorithm searches for the best split using a **random subset of features**. The number of features is controlled by the parameter `max_features`. We have used the default, which is the square root of the number of columns of the feature matrix (`max_features=sqrt`). This means, in this case, 28 features. Logic tells us that, by increasing `max_features`, we will improve the accuracy, but the learning process (the fit step) will get slower. Try some variations on this, to see how it works in practice. Do you think that using the default number of features here was a good choice?\n",
    "\n",
    "2. Develop a **gradient boosting classifier** for these data, extracted from the `xgboost` class `XGBClassifier()`. Take into account that, with hundreds of columns, a gradient boosting model may be much slower to train than a random forest model with the same tree size and number of trees. A model with 100 trees and a size similar to those shown in this example can take one hour to train (less with XGBoost), though you may find a speed-up by increasing the **learning rate**.\n",
    "\n",
    "3. Develop a **logistic regression classifier** for these data. Compare it with the other models that have appeared in this example.\n",
    "\n",
    "4. Calculate a **confusion matrix** for the logistic regression model (dimension 10x10). Which is the best classified digit? Which is the main source of misclassification?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
