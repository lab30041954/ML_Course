{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21275a45-665e-4241-992a-e7c2184da6bf",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lab30041954/ML_IESE_Course/blob/main/%5BML-06%5D%20Neural%20networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a62669-8740-4cf2-9ad1-7b3026ca9717",
   "metadata": {
    "id": "38a62669-8740-4cf2-9ad1-7b3026ca9717"
   },
   "source": [
    "# [ML-06] Neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8a58c-4af7-4db5-90be-afea96be21bf",
   "metadata": {
    "id": "92e8a58c-4af7-4db5-90be-afea96be21bf"
   },
   "source": [
    "## What is a neural network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5729299d-2e92-40b8-b366-1e2c751606fd",
   "metadata": {
    "id": "5729299d-2e92-40b8-b366-1e2c751606fd"
   },
   "source": [
    "**Neural networks** are as old as artificial intelligence itself, and the expectations about what neural networks could do have experimented up and downs along 60 years. Right now, they are very high. Neural networks and, more specifically, a special type of neural network models, the **transformer**, are taking over machine learning. As more use cases are reported for the new models, expectations about the power of artificial intelligence keep growing.  \n",
    "\n",
    "A neural network can be thought as an interconnected set of computational **nodes** or neurons, organized in **layers**. In the network, every connection of a node to another node has a **weight**. Machine learning happens when these weights are learned from data. The way the nodes are connected in a neural network was initially inspired by ideas about neurons work together in the brain. Though this is no longer true in most nueral network models, in particular in transformers, the discussion about the similarities between the two domains is still alive.\n",
    "\n",
    "There are many types of neural networks. This lecture is restricted to the **multilayer perceptron** (MLP) model, which has been the standard approach for many years. In the next lecture, we will introduce more complex architectures, which are usually presented as **deep learning** models.\n",
    "\n",
    "Even if the idea of the neural network as a mathematical model for the brain (which it is not) was attractive, we regard nowadays a neural network as a mathematical function, which takes an input and returns an output. Both the input and the output are **tensors**. A tensor is the same as a NumPy array (though in Python they are different types of objects). So, a 0D tensor is a scalar (a number), a 1D tensor is a vector, a 2D tensor is a matrix, etc. Most of the operations performed with the tensors in a neural network are just linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048e217-b3d8-427b-b33a-de483afd9e87",
   "metadata": {
    "id": "7048e217-b3d8-427b-b33a-de483afd9e87"
   },
   "source": [
    "## Basics of the MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4739cf-511c-4b54-933e-e5fd6103294e",
   "metadata": {
    "id": "6e4739cf-511c-4b54-933e-e5fd6103294e"
   },
   "source": [
    "A multilayer perceptron network is formed by:\n",
    "\n",
    "* The **input layer**, whose nodes are the features used for the prediction.\n",
    "\n",
    "* The **output layer**. In regression models, it has a unique node, which is the target (as in the above figure), while, in classification models, it has one node for every target value.\n",
    "\n",
    "* A sequence of **hidden layers**, placed between the input and the output layers. If the network is **fully-connected**, that is, if every node of a layer is connected to all the nodes of the following layer, the **network architecture** is completely specified by the number of hidden layers and the number of nodes in each hidden layer.\n",
    "\n",
    "So the MLP model transforms a 1D tensor of features into either a 0D tensor (regression) or a 1D tensor of class probabilities. These tensors are the input and the output, respectively. How is the transformation performed? Suppose first that $Z$ is a hidden node and $U_1, U_2, \\dots, U_k$ are the nodes of the preceding layer. Then, the values of $Z$ are calculated as\n",
    "\n",
    "$$Z = F\\big(w_0 + w_1U_1 + w_2U_2 + \\cdots + w_kU_k\\big).$$\n",
    "\n",
    "In this context, the slope coefficients $w_1, w_2, \\dots, w_k$  are called weights, and the intercept $w_0$ is called **bias**. $F()$ is the **activation function**.\n",
    "\n",
    "The multilayer perceptron could be seen as if the samples were circulating through the network one-by-one. The feature values are entered in the input nodes, which send them to the nodes of the first hidden layer. At each hidden node, they are combined using the corresponding weights, and the result is transformed by means of the activation function. The hidden nodes send the resulting values to the nodes of the next layer, where they are combined. And so on, until arriving to the output layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a492258f-5640-455b-9a1f-216bc03d99ec",
   "metadata": {
    "id": "a492258f-5640-455b-9a1f-216bc03d99ec"
   },
   "source": [
    "## A graphical example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c25c58b-da19-4061-aa91-c115245a7ac8",
   "metadata": {
    "id": "2c25c58b-da19-4061-aa91-c115245a7ac8"
   },
   "source": [
    "Let us help our intuition with the graphical representation of a small network. The model of the figure below is an MLP regressor with one hidden layer of two nodes. The diagram is just a graphical representation of a set of three equations, two for the hidden nodes and one for the output node. The equation of node $A$ combines $X_1$, $X_2$ and $X_3$ with weights $w_{1A}$, $w_{2A}$ and $w_{3A}$, while the equation in node $B$ combines them with weights $w_{1B}$, $w_{2B}$ and $w_{3B}$. The biases are $w_{0A}$ and $w_{0B}$, respectively.\n",
    "\n",
    "![](https://raw.githubusercontent.com/lab30041954/Figures/main/nn.png)\n",
    "\n",
    "At the hidden nodes, the **activation function** is applied to the values given by these equations. Once the activation has been applied, the outcomes of the two hidden nodes are combined in the third equation, with weights $w_{AY}$ and $w_{BY}$ and bias $w_{0Y}$, to obtain the predicted value of $Y$. This model has a total of 11 parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5218790-5d5d-4c01-b2c3-df2fb828f58c",
   "metadata": {
    "id": "d5218790-5d5d-4c01-b2c3-df2fb828f58c"
   },
   "source": [
    "## The activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627ceca8-b763-45bd-a59c-2a7feade770c",
   "metadata": {
    "id": "627ceca8-b763-45bd-a59c-2a7feade770c"
   },
   "source": [
    "The choice of the activation function is based on performance, since we do not have any serious theory that could explain why a specific mathematical formula works better than others. Just a few years ago, the **logistic function** was the recommended activation function in the hidden layers, although some preferred a similar formula called the **hyperbolic tangent** function. The current trend favors the **rectified linear unit function** ($\\hbox{ReLU}$). $\\hbox{ReLU}(x)$ is equal to $x$ when $x>0$ and equal to $0$ otherwise. So, the default activation in the hidden layers consists in turning the negative incoming values into zeros.\n",
    "\n",
    "In a MLP regressor (as in the figure), there is no activation at the (single) output node, so the equation predicting the values at that node is linear. In a MLP classifier, there are as many output nodes as target values. A **softmax activation** is applied to the whole set of incoming values, turning them into a set of **class probabilities**. In mathematical terms, this is the same as logistic regression applied to the output of the last hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975ec9e-ed2c-4e86-b0bf-5f4fa063b633",
   "metadata": {
    "id": "1975ec9e-ed2c-4e86-b0bf-5f4fa063b633"
   },
   "source": [
    "## Other technicalities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3407e7f-dd91-4f88-9e7b-58fc7258f8b4",
   "metadata": {
    "id": "f3407e7f-dd91-4f88-9e7b-58fc7258f8b4"
   },
   "source": [
    "* *How to find the optimal weights*. Initially, the weights are randomly assigned. Then, an iterative process starts. At every step, the prediction is performed with the current weights, the value of a **loss function** is calculated, and the weights are adjusted in order to reduce the loss. The process is expected to converge to an optimal solution, but, in practice, a maximum number of passes is pre-specified. In regression, the loss is usually the MSE, while, in classification, it is the average cross-entropy (Keras uses natural logs to calculate it). The adjustment of the weights starts at the last layer, and continues backwards until the input layer. This is called **backpropagation**.\n",
    "\n",
    "* *The optimization method*, called **solver** in scikit-learn and **optimizer** in the Keras API. The current trend favors the **stochastic gradient descent** (SGD) method, which has many variants. Though you may find in books or tutorials the variant `optimizer='rmsprop'`, we use here `optimizer='adam'`, which is faster.\n",
    "\n",
    "* *The number of iterations*, that is, the number of times every sample passes through the network is controlled in Keras with the parameter **epochs**. The default is `epochs=1`. In SGD, the samples don't pass all at once, but in **random batches** (see below).\n",
    "\n",
    "* *The batch size*. In the SGD method, the training data are randomly partitioned in batches in every iteration. The batches are tried one-by-one and the weights are modified every time that a batch is tried. The Keras default is `batch_size=32`. We don't change this in the examples of this course.\n",
    "\n",
    "* *The learning rate*, which we have already found in gradient boosting models, is a parameter which rules how fast the adjustment of the weights is done. If it is too low, there is no convergence to the optimal solution. If it is too high, you can overshoot the optimal solution. Modern ML software allows setting an initial learning rate and decrease it as the learning process goes on. The Keras default is `learning_rate=0.001`.\n",
    "\n",
    "* *Normalization*. Optimization methods are sensitive to feature scaling, so it is highly recommended to scale your data. In the old data mining suites, normalization was applied as a part of the algorithm, and the output was scaled back to the original range. It is not so in the Python ML toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6b4a1e-b1e2-4654-afdd-c50029b8706b",
   "metadata": {
    "id": "1f6b4a1e-b1e2-4654-afdd-c50029b8706b"
   },
   "source": [
    "## TensorFlow, Torch and Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5f711c-f520-492d-8c43-52d517646da6",
   "metadata": {
    "id": "8c5f711c-f520-492d-8c43-52d517646da6"
   },
   "source": [
    "A number of attempts have been made to implement the mathematics of neural networks. Many of them are just history nowadays. The library **TensorFlow**, developed at Google Brain and released in 2015, has been for years the top popular choice, though the field seems to be divided right now between TensorFlow and **Torch** (PyTorch in Python).\n",
    "\n",
    "**Keras** is a deep learning framework for Python (there is also a version for R), which provides a convenient way to define and train neural network models. The documentation is available at `https://keras.io`. Keras does not handle itself low-level operations such as tensor manipulation and differentiation. Instead, it relies on a specialized tensor library to do so. That library serves as the **backend** engine of Keras.\n",
    "\n",
    "Keras was organized in a modular way, so several different backend engines could be plugged seamlessly into Keras. Keras 1 worked with three backend implementations, TensorFlow, Theano and CNTK. Given the dominance of TensorFlow, the last two options were dropped, so Keras 2 was no longer multi-backend, becoming just an API for TensorFlow. In November 2023, Keras 3 came again multi-backend, the optional backends being TensorFlow, Torch and JAX (a new Google development).\n",
    "\n",
    "Just to give you an idea why Keras is popular, it has been said that the number of keystrokes needed to specify a deep learning model in Keras is one half of what was needed in old TensorFlow. Another advantage is that the code written in Keras by a developer using TensorFlow can be reused without change by another developer using Torch. Even if Torch tensors and TensorFlow tensors are different types of objects in Python, Keras takes care of that, and input and output tensors appear as NumPy arrays, which is the only thing you have to manage in Keras.\n",
    "\n",
    "This course uses Keras with the default backend, which is TensorFlow. To use this notebook in your computer, you have to install Keras and TensorFlow. You can do that by entering in either the shell or a Jupyter app the command\n",
    "\n",
    "```\n",
    "pip install keras tensorflow\n",
    "```\n",
    "\n",
    "This is not needed in Google Colab, where everything is ready for the Keras/TensorFlow combo. When this is written, TensorFlow has not been updated for Python 3.13, which is the version coming with the current Anaconda distribution (there is no problem if you are still using Python 3.12 or older). You can skip this potential trouble running the notebook in Colab. The code used in the example will be explained there step-by-step.\n",
    "\n",
    "*Note*. MLP models for regression and classification are available in scikit-learn, in the classes `MLPRegressor()` and `MLPClassifier()` of the subpackage `neural_networks`, but scikit-learn does not cover the advanced methodology needed in this part of the course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b7d43a-fa55-4ca6-ba17-5141fc293413",
   "metadata": {
    "id": "b3b7d43a-fa55-4ca6-ba17-5141fc293413"
   },
   "source": [
    "## Example - The MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7541389-25ba-4302-85e2-1b1d73073785",
   "metadata": {
    "id": "f7541389-25ba-4302-85e2-1b1d73073785"
   },
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9737b3a7-6622-45db-908f-ef9e64092901",
   "metadata": {
    "id": "9737b3a7-6622-45db-908f-ef9e64092901"
   },
   "source": [
    "This example deals with the classification of grayscale images of handwritten digits (resolution 28 $\\times$ 28), into 10 classes (0 to 9). The data are the famous **MNIST data**, a classic in the ML community, which have been around for almost as long as the field itself and have been very intensively studied.\n",
    "\n",
    "The MNIST data set contains 60,000 training images, plus 10,000 test images, assembled by the National Institute of Standards and Technology (NIST) in the 1980s. They have been extensively used for benchmarking. You can think of \"solving\" MNIST as the \"Hello World\" of deep learning. As you become an ML practitioner, the MNIST data come up over and over again, in scientific papers, blog posts, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8680ab7b-db99-45f2-8db7-98a0b0cbfedd",
   "metadata": {
    "id": "8680ab7b-db99-45f2-8db7-98a0b0cbfedd"
   },
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc15b246-f095-4aed-9c24-224c26297a24",
   "metadata": {
    "id": "fc15b246-f095-4aed-9c24-224c26297a24"
   },
   "source": [
    "The data of the 70,000 images come together in the file `mnist.csv` (zipped). Every row stands for an image. The first column is a label identifying the digit (0-9). The other 784 columns correspond to the image pixels (28 $\\times$ 28 = 784). The column name `ixj` must be read as the gray intensity of the pixel in row $i$ and column $j$ (in the images). These intensities are integers from 0 = Black to 255 = White (8-bit grayscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e56555-b023-456c-8d4f-f2b6ab6a7b5d",
   "metadata": {
    "id": "27e56555-b023-456c-8d4f-f2b6ab6a7b5d"
   },
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d412391-059e-4e64-b6d1-5d4502fc9939",
   "metadata": {
    "id": "6d412391-059e-4e64-b6d1-5d4502fc9939"
   },
   "source": [
    "Q1. Pick the first digit image (row 1). The 784 entries on the right of the label, from `1x1` to `28x28`, are the pixels' gray intensities. Pack these numbers as a vector and reshape that vector as a matrix of 28 rows and 28 columns. Plot the corresponding image with the `matplotlib.pyplot` function `imshow()`. This function will be using default colors which do not help here, so you can turn everything to gray scale by executing the function `gray()`. Your plot will have then black background, with the number drawn in white. Guess how to reverse this, so the image looks like white paper with a number drawn in black ink.\n",
    "\n",
    "Q2. Repeat the exercise with other images. You don't need the function `gray()` anymore.\n",
    "\n",
    "Q3. Split the data in a training set with 60,000 data units and a test set with 10,000 units.\n",
    "\n",
    "Q4. Train and test a **decision tree classifier** and a **random forest classifier** on these data, controlling the growth of the trees with the argument `max_leaf_nodes=128`.\n",
    "\n",
    "Q5. Train and test a MLP model, with a hidden layer of 32 nodes, using that split.\n",
    "\n",
    "Q6. How does the MLP model make predictions?\n",
    "\n",
    "Q7. Convert the gray scale to the 0-1 range (0 = Black, 1 = White), and try again with the same MLP architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb953da4-3352-49fb-a42e-86b0600bc61a",
   "metadata": {
    "id": "cb953da4-3352-49fb-a42e-86b0600bc61a"
   },
   "source": [
    "### Importing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65414bb-8447-42c0-85cc-34553b0209f8",
   "metadata": {
    "id": "e65414bb-8447-42c0-85cc-34553b0209f8"
   },
   "source": [
    "As in the preceding examples, we use the Pandas function `read_csv()` to import the data from a GitHub repository. Since the images do not have an identifier, we leave Pandas to create a `RangeIndex`. The source file is zipped, but `read_csv()` can manage this without a specific argument, based on the file extension `.zip`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa0681e1-e301-49a5-8d27-f18c58e97adc",
   "metadata": {
    "id": "fa0681e1-e301-49a5-8d27-f18c58e97adc"
   },
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "path = 'https://raw.githubusercontent.com/lab30041954/Data/main/'\n",
    "df = pd.read_csv(path + 'mnist.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fdc772-8a2c-4729-88d7-4c4fc7e5dc1b",
   "metadata": {
    "id": "07fdc772-8a2c-4729-88d7-4c4fc7e5dc1b"
   },
   "source": [
    "We check the shape of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdfb26ba-b302-4600-9c2e-a20ec2ac000f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdfb26ba-b302-4600-9c2e-a20ec2ac000f",
    "outputId": "106fe09b-50d3-4e1b-bc83-ee3679cdb92b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 785)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2730d4ef-e5f3-4b27-abb4-e90d012d6b50",
   "metadata": {
    "id": "2730d4ef-e5f3-4b27-abb4-e90d012d6b50"
   },
   "source": [
    "### Target vector and features matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb488669-bba3-43fe-8680-76da5a7ac1b4",
   "metadata": {
    "id": "fb488669-bba3-43fe-8680-76da5a7ac1b4"
   },
   "source": [
    "We set the first column (the image labels) as the target vector and the pixel intensities as the feature matrix. We use only NumPy arrays in this example, to simplify the syntax. So, we convert the Pandas objects to arrays by means of `.values`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897e5038-cc82-49e1-9e10-a68de4dd7987",
   "metadata": {
    "id": "897e5038-cc82-49e1-9e10-a68de4dd7987"
   },
   "outputs": [],
   "source": [
    "y = df['label'].values\n",
    "X = df.drop(columns='label').values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd6652-75ea-4ad0-bd99-0ba18127a72c",
   "metadata": {
    "id": "32bd6652-75ea-4ad0-bd99-0ba18127a72c"
   },
   "source": [
    "We can examine the labels the NumPy function `unique()`. This shows that the data are a bit unbalanced: ones are most frequent, and fives least frequent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91b9aca-293b-4063-82b3-f664cd4c46f9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b91b9aca-293b-4063-82b3-f664cd4c46f9",
    "outputId": "56f0e0e6-29b8-4e59-c7dc-73e6e5e92844"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       " array([6903, 7877, 6990, 7141, 6824, 6313, 6876, 7293, 6825, 6958]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8539bbe6-a5f6-4f49-a6a4-b5bfc1414459",
   "metadata": {
    "id": "8539bbe6-a5f6-4f49-a6a4-b5bfc1414459"
   },
   "source": [
    "The pixel values can also be checked with `unique()`. We don't calculate here the counts for the 256 values, to keep it short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f87673f-39e1-4088-8f89-70c2cbc985d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8f87673f-39e1-4088-8f89-70c2cbc985d1",
    "outputId": "a2f35273-3c81-4847-d423-c432c3101585"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "       247, 248, 249, 250, 251, 252, 253, 254, 255])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a8324-896d-4824-bcef-87ddc962ec0e",
   "metadata": {
    "id": "bf3a8324-896d-4824-bcef-87ddc962ec0e"
   },
   "source": [
    "### Q1. Plotting the first image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160bb09-731b-4b46-b64e-493eeaa0fa66",
   "metadata": {
    "id": "5160bb09-731b-4b46-b64e-493eeaa0fa66"
   },
   "source": [
    "Every row corresponds to the image of a digit. Let us visualize this by plotting the images with Matplotlib. In the first row, the 784 entries, from 1 $\\times$ 1 to 28 $\\times$ 28, are the pixels' gray intensities. To plot the image, we have to reshape it as a 2D array with 28 rows and 28 columns. This can be done with the method `.reshape()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbec20db-4cc7-472a-9282-8acf6a7fb430",
   "metadata": {
    "id": "bbec20db-4cc7-472a-9282-8acf6a7fb430"
   },
   "outputs": [],
   "source": [
    "pic = X[0, :].reshape(28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1199d120-1058-4e4b-96f8-2aed7e27b4e3",
   "metadata": {
    "id": "1199d120-1058-4e4b-96f8-2aed7e27b4e3"
   },
   "source": [
    "The `matplotlib.pyplot` function `imshow()` converts this array to a picture and displays it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86984516-f037-4cee-991a-15e6f5fd5bd1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "86984516-f037-4cee-991a-15e6f5fd5bd1",
    "outputId": "40153455-0f10-4405-d128-65f349515f34"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4dfea-3235-417a-8e76-e1b86582f4b5",
   "metadata": {
    "id": "fcd4dfea-3235-417a-8e76-e1b86582f4b5"
   },
   "source": [
    "These are the default colors displayed by `imshow()`. To turn them into gray scale, one can use the argument `cmap='gray'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4c92b75-40c5-4e88-b8c5-87dc0c6fa60a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "b4c92b75-40c5-4e88-b8c5-87dc0c6fa60a",
    "outputId": "c6d1ee2b-349f-469e-d132-169529e1da5a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pic, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18002e1-55b7-4322-be4b-5f5d8c2bf7bf",
   "metadata": {
    "id": "d18002e1-55b7-4322-be4b-5f5d8c2bf7bf"
   },
   "source": [
    "The gray scale can be set as the default with the function `gray()`. Now, reversing the scale, we can show the picture as it were a digit written with black pencil on a white paper surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e10cce1-54c1-4897-b99b-48283de5d709",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "6e10cce1-54c1-4897-b99b-48283de5d709",
    "outputId": "6452c673-52e8-4300-fa13-fc9c63bc142e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "plt.imshow(255 - pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824a8d1-95ce-4578-adca-9e609057a69b",
   "metadata": {
    "id": "0824a8d1-95ce-4578-adca-9e609057a69b"
   },
   "source": [
    "This five is far from caligraphic, but still recognizable by a human eye."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06fd214-959e-4050-90dc-398c482c460e",
   "metadata": {
    "id": "b06fd214-959e-4050-90dc-398c482c460e"
   },
   "source": [
    "### Q2. Plotting other images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3db2d2-98d1-4cab-8eec-4c21f256c781",
   "metadata": {
    "id": "5e3db2d2-98d1-4cab-8eec-4c21f256c781"
   },
   "source": [
    "The second image of the data set is a zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e91c9487-d8f9-4faa-bed9-49e878c1c7cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "e91c9487-d8f9-4faa-bed9-49e878c1c7cb",
    "outputId": "8b09d7c0-2bb5-4d0a-c38f-4a0200b737b2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pic = X[1, :].reshape(28,28)\n",
    "plt.imshow(255 - pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4458ca35-03be-4ba4-a5ce-d124fea86d5c",
   "metadata": {
    "id": "4458ca35-03be-4ba4-a5ce-d124fea86d5c"
   },
   "source": [
    "And the third one a four:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47637827-a3f6-433c-9bb4-f34b1b8df959",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "47637827-a3f6-433c-9bb4-f34b1b8df959",
    "outputId": "db239221-0426-4c88-d4be-26eab56133a9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pic = X[2, :].reshape(28,28)\n",
    "plt.imshow(255 - pic);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfa0c9b-0ae2-4277-bef0-db6f3756a212",
   "metadata": {
    "id": "3cfa0c9b-0ae2-4277-bef0-db6f3756a212"
   },
   "source": [
    "### Q3. Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc0a1a-aff4-44ec-98bc-3d8e3472a80b",
   "metadata": {
    "id": "99dc0a1a-aff4-44ec-98bc-3d8e3472a80b"
   },
   "source": [
    "We split the data set, so we can validate the models that we will try. We keep 10,000 pictures for testing, which is common practice with the MNIST data. We set `random_state=0` for reproducibility. So, we will be able to rescale the features and apply the same split to the rescaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35bbb944-be3f-46f4-85d5-b20916c95a40",
   "metadata": {
    "id": "35bbb944-be3f-46f4-85d5-b20916c95a40"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/7, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d234f78d-ba8d-456a-84ab-1d3197fb53fc",
   "metadata": {
    "id": "d234f78d-ba8d-456a-84ab-1d3197fb53fc"
   },
   "source": [
    "### Q4. Tree-based models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d1e72c-d7a3-45ba-900e-09e03b41ab00",
   "metadata": {
    "id": "17d1e72c-d7a3-45ba-900e-09e03b41ab00"
   },
   "source": [
    "We start with a decision tree classifier, to get a first benchmark. We use an estimator from the class `DecisionTreeClassifier()`, of the scikit-learn subpackage `tree`. Given the size of the data set, we set `max_leaf_nodes=128`, to control the growth of the tree. We calculate the accuracy on both training and test data. The accuracy can be a good way to evaluate this model, since the data set is quite balanced and we don't have any preference for a particular digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a9cbc91-e532-4866-b353-5a39c7e1299d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a9cbc91-e532-4866-b353-5a39c7e1299d",
    "outputId": "f4ee3a61-eec0-464d-c150-84654307c087"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.809, 0.791)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "treeclf = DecisionTreeClassifier(max_leaf_nodes=128)\n",
    "treeclf.fit(X_train, y_train)\n",
    "round(treeclf.score(X_train, y_train), 3), round(treeclf.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043e2958-ba97-4cc7-9063-d26bcde75a79",
   "metadata": {
    "id": "043e2958-ba97-4cc7-9063-d26bcde75a79"
   },
   "source": [
    "Even if the tree is big, we don't find evidence of overfitting. The accuracy is not negligeable, but would not be enough for business applications. For instance, to be used on scanned zipcodes (five digits). Maintaining the specification for the tree size, we try now a random forest classifier with 100 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b772cf7b-287a-4f11-968f-386ef4dec2fd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b772cf7b-287a-4f11-968f-386ef4dec2fd",
    "outputId": "edcc1043-d3d0-4e65-bcda-61f6c6395e76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.927, 0.917)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfclf = RandomForestClassifier(max_leaf_nodes=128, n_estimators=100)\n",
    "rfclf.fit(X_train, y_train)\n",
    "round(rfclf.score(X_train, y_train), 3), round(rfclf.score(X_test, y_test), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca4c99d-cbce-467b-a20c-2a0a985b4318",
   "metadata": {
    "id": "5ca4c99d-cbce-467b-a20c-2a0a985b4318"
   },
   "source": [
    "This is clearly better than an individual tree, and overfitting is moderate. The homework suggests that you can improve this a bit more by changing the specs. You can also try a gradient boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736f569-9e29-495d-8314-d16148507d08",
   "metadata": {
    "id": "4736f569-9e29-495d-8314-d16148507d08"
   },
   "source": [
    "### Q5. MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e1d03d-bdcb-4201-bbcd-190d3a5af76a",
   "metadata": {
    "id": "62e1d03d-bdcb-4201-bbcd-190d3a5af76a"
   },
   "source": [
    "We try now a simple neural network, using the Keras, with the TensorFlow backend. Assuming that Keras and TensorFlow are already installed and everything is all right (it will be if run this notebook in Google Colab), we import the function `Input()` and the modules `models` and `layers`, which contain the resources needed for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec5efbda-feec-495a-a657-00a347b3bca3",
   "metadata": {
    "id": "ec5efbda-feec-495a-a657-00a347b3bca3"
   },
   "outputs": [],
   "source": [
    "from keras import Input, models, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d750f-5f22-4293-9444-22fba2d41211",
   "metadata": {
    "id": "2c0d750f-5f22-4293-9444-22fba2d41211"
   },
   "source": [
    "The module `models` has two classes, `.Sequential()` and `.Model()`. The first one can only specify a network architecture made of a sequence of layers. The other class, known as the **Functional API**, does not have that restriction. We use `.Model()` in this course.\n",
    "\n",
    "A simple way to specify the network architecture is to create a list of layers. The layers are extracted from classes of the module `layers`. For a MLP network we only need the class `Dense()`. For instance, a MLP network with one hidden layer of 32 nodes for the MNIST data would be specified as follows. First, the **input layer** contains one node for every feature (there 784 features, one for each pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c09be2ff-d5f8-4ce4-af7b-3f772a31f96e",
   "metadata": {
    "id": "c09be2ff-d5f8-4ce4-af7b-3f772a31f96e"
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee86f730-cca8-4f88-9977-7cff0158148b",
   "metadata": {
    "id": "ee86f730-cca8-4f88-9977-7cff0158148b"
   },
   "source": [
    "Next, the **hidden layer**, that transforms the input tensor (length 784) into a new tensor (length (32). It is a dense layer, meaning that every node is connected to all nodes of the preceding layer. The activation function is the **rectified linear unit function** (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "563a762b-6aa5-4b8c-8073-3455dbea9c0b",
   "metadata": {
    "id": "563a762b-6aa5-4b8c-8073-3455dbea9c0b"
   },
   "outputs": [],
   "source": [
    "x = layers.Dense(32, activation='relu')(input_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ed95aa-88c8-4841-b697-de029802dc0b",
   "metadata": {
    "id": "a8ed95aa-88c8-4841-b697-de029802dc0b"
   },
   "source": [
    "Finally, the **output layer** transforms the hidden tensor (length 32) into a tensor of class probabilities (length 10). The activation function is here the **softmax**, which ensures that the output is a vector of probabilities (positive numbers summing 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cff7193-3581-4b0e-99ba-22890f731690",
   "metadata": {
    "id": "0cff7193-3581-4b0e-99ba-22890f731690"
   },
   "outputs": [],
   "source": [
    "output_tensor = layers.Dense(10, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f907eb-6b3c-4d29-8d5c-c8e2c106b3c8",
   "metadata": {
    "id": "08f907eb-6b3c-4d29-8d5c-c8e2c106b3c8"
   },
   "source": [
    "The next step is instantiate an object of the class `models.Model()`. This works as in scikit-learn. We specify here the input and the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e3fa44-c5bc-4a16-b5bf-28cecaa7ddae",
   "metadata": {
    "id": "26e3fa44-c5bc-4a16-b5bf-28cecaa7ddae"
   },
   "outputs": [],
   "source": [
    "mlpclf1 = models.Model(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e158336-b981-4e3c-bf8a-34c84e0067dd",
   "metadata": {
    "id": "8e158336-b981-4e3c-bf8a-34c84e0067dd"
   },
   "source": [
    "The method `.summary()` prints a summary of the network architecture, reporting the number of parameters in every layer. In the hidden layer, every node receives 784 inputs (one for each pixel), which are combined wby means of a linear expression involving the same number of **weights** (the slope coefficients) plus a **bias** (the intercept). So, 785 parameters are needed at every node, which makes a total of 32 $\\times$ 785 = 25,120 parameters. In a similar way, in the output layer, every node needs 33 parameters, which adds 10 $\\times$ 33 = 330 parameters to get a total of 25,450 parameters for the whole network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec50f670-643a-4978-a705-11a85e491b7e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "id": "ec50f670-643a-4978-a705-11a85e491b7e",
    "outputId": "30928f52-fd13-4133-f769-8cffcfb452e1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">25,120</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m25,120\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m330\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,450</span> (99.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,450\u001b[0m (99.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,450</span> (99.41 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m25,450\u001b[0m (99.41 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlpclf1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f24051-cb52-4643-9c8f-e79edbe28ad9",
   "metadata": {
    "id": "69f24051-cb52-4643-9c8f-e79edbe28ad9"
   },
   "source": [
    "Now, we **compile** the model, meaning the mathematical apparatus needed for the learning process gets ready. We have to specify the **optimization algorithm** (`optimizer='adam'`), the **loss function** (`loss='sparse_categorical_crossentropy'`) and the metrics used to evaluate the model performance (`metrics=['acc']`), in a list or dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1d0f2c5-bb04-49a7-bfb2-248b7d8aa2ad",
   "metadata": {
    "id": "b1d0f2c5-bb04-49a7-bfb2-248b7d8aa2ad"
   },
   "outputs": [],
   "source": [
    "mlpclf1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc88510-1993-4082-8008-36b719faee3e",
   "metadata": {
    "id": "8fc88510-1993-4082-8008-36b719faee3e"
   },
   "source": [
    "We are ready now to apply the method `.fit()`. Note that the number of iterations is specified here, not when creating the model, as it was in scikit-learn. In every iteration, or **epoch**, the data set is randomly split in batches of size 32 (if you accept the deafult size). These batches are passed sequentially, and the parameter values are updated for every batch. This means that they not are updated 50 times, but 50 times the number of batches (1,875). By default, a report of the progress is gradually displayed on the screen. In this example, every epoch takes about nine seconds in a regular laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "90b9d62b-e0b9-4a00-aa10-996b73a7e748",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "90b9d62b-e0b9-4a00-aa10-996b73a7e748",
    "outputId": "cab51e20-dec5-475f-a35f-23864a61c32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - acc: 0.5683 - loss: 6.6453 - val_acc: 0.7672 - val_loss: 0.7716\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - acc: 0.8135 - loss: 0.6595 - val_acc: 0.8769 - val_loss: 0.5359\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.8758 - loss: 0.4858 - val_acc: 0.8922 - val_loss: 0.4266\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - acc: 0.9039 - loss: 0.3787 - val_acc: 0.9053 - val_loss: 0.3687\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9160 - loss: 0.3328 - val_acc: 0.9014 - val_loss: 0.3693\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - acc: 0.9238 - loss: 0.2980 - val_acc: 0.9247 - val_loss: 0.3278\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - acc: 0.9307 - loss: 0.2751 - val_acc: 0.9240 - val_loss: 0.3096\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - acc: 0.9319 - loss: 0.2656 - val_acc: 0.9275 - val_loss: 0.3370\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9365 - loss: 0.2518 - val_acc: 0.9231 - val_loss: 0.3693\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9381 - loss: 0.2460 - val_acc: 0.9213 - val_loss: 0.3192\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - acc: 0.9390 - loss: 0.2376 - val_acc: 0.9249 - val_loss: 0.3500\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9398 - loss: 0.2406 - val_acc: 0.9314 - val_loss: 0.3210\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9416 - loss: 0.2284 - val_acc: 0.9149 - val_loss: 0.3536\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9434 - loss: 0.2325 - val_acc: 0.9285 - val_loss: 0.3224\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9436 - loss: 0.2267 - val_acc: 0.9260 - val_loss: 0.3212\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - acc: 0.9447 - loss: 0.2203 - val_acc: 0.9276 - val_loss: 0.3574\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9443 - loss: 0.2207 - val_acc: 0.9321 - val_loss: 0.3231\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9481 - loss: 0.2038 - val_acc: 0.9118 - val_loss: 0.4384\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9442 - loss: 0.2195 - val_acc: 0.9229 - val_loss: 0.3611\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - acc: 0.9451 - loss: 0.2175 - val_acc: 0.9292 - val_loss: 0.3855\n"
     ]
    }
   ],
   "source": [
    "mlpclf1.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "goQg5XU8zCqr",
   "metadata": {
    "id": "goQg5XU8zCqr"
   },
   "source": [
    "This is our best result so far, though we can do better with a gradient boosting model, as suggested in the homework, or by rescaling the data, as suggested in question Q7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932e4392-c9dd-4817-b13b-0e3532533de8",
   "metadata": {
    "id": "932e4392-c9dd-4817-b13b-0e3532533de8"
   },
   "source": [
    "### Q6. Prediction with a MLP model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77419e4f-4cb1-4a94-977e-85c973ed83f1",
   "metadata": {
    "id": "77419e4f-4cb1-4a94-977e-85c973ed83f1"
   },
   "source": [
    "In a classification setting, the Keras method `.predict()` returns the class probabilities (not the predicted class), just as the scikit-learn method `.predict_proba()`. In this example, it returns, for a given input, the 10 values given by the softmax activation at the output nodes, which are the **predicted class probabilities** for that input. For instance, for the first digit of the test set, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d909f5f-72cc-459e-9791-80b75e1ec62e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9d909f5f-72cc-459e-9791-80b75e1ec62e",
    "outputId": "ebf10cd4-81dd-43f1-e750-e1da1cd23ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[9.8997855e-01, 2.4395902e-06, 1.8417242e-04, 2.6305972e-07,\n",
       "        1.7291821e-05, 1.9600892e-03, 2.8388551e-05, 7.7114701e-06,\n",
       "        6.2834258e-09, 7.8210300e-03]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlpclf1.predict(X_test[:1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h1fMOc750_1h",
   "metadata": {
    "id": "h1fMOc750_1h"
   },
   "source": [
    "According to the model, with probability 99.0%, this is a zero. Indeed, the prediction is correct:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "IsciAc_21Hm8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IsciAc_21Hm8",
    "outputId": "8121b226-addb-4cf6-bb17-be4130fbbbe1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086d1d39-dba6-43cd-8f31-e5db5bfb607c",
   "metadata": {
    "id": "086d1d39-dba6-43cd-8f31-e5db5bfb607c"
   },
   "source": [
    "### Q7. Rescaling the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d7fc6-5d5c-47b6-8f76-2d8c458ee65d",
   "metadata": {
    "id": "bb5d7fc6-5d5c-47b6-8f76-2d8c458ee65d"
   },
   "source": [
    "As a general rule, it is recommended to rescale the features to the 0-1 range. This speeds up the convergence and may improve the predictions. In this example, we can rescale the pixel intensities by dividing by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8ff0601-1827-4632-8e88-723fe6ebda59",
   "metadata": {
    "id": "a8ff0601-1827-4632-8e88-723fe6ebda59"
   },
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46842bb6-40c8-41fc-be8b-7bf33de7aa9d",
   "metadata": {
    "id": "46842bb6-40c8-41fc-be8b-7bf33de7aa9d"
   },
   "source": [
    "We have now a new features matrix, that we split exactly in the same way as we did with before (the argument `random_state=0` does the trick)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7bb87767-2a0b-4aaa-80b7-6ba0e9d15382",
   "metadata": {
    "id": "7bb87767-2a0b-4aaa-80b7-6ba0e9d15382"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=1/7, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddec606b-2c5d-4c55-a9c9-2958378f7308",
   "metadata": {
    "id": "ddec606b-2c5d-4c55-a9c9-2958378f7308"
   },
   "source": [
    "Now, we instantiate a new model, which we train on the rescaled data. We keep `epochs=20`, even if we guess that so many epochs are not needed. The training process is not only faster, achieving accuracy 93.3% in the first epoch, but it also yields better results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22c400ed-01b3-4bd1-a25a-f46713c0e824",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22c400ed-01b3-4bd1-a25a-f46713c0e824",
    "outputId": "21904665-d275-41ea-c82b-0b74270ad96c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.7422 - loss: 0.9395 - val_acc: 0.9330 - val_loss: 0.2299\n",
      "Epoch 2/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9416 - loss: 0.2038 - val_acc: 0.9457 - val_loss: 0.1827\n",
      "Epoch 3/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9543 - loss: 0.1588 - val_acc: 0.9496 - val_loss: 0.1672\n",
      "Epoch 4/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - acc: 0.9598 - loss: 0.1381 - val_acc: 0.9528 - val_loss: 0.1512\n",
      "Epoch 5/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - acc: 0.9638 - loss: 0.1225 - val_acc: 0.9549 - val_loss: 0.1433\n",
      "Epoch 6/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - acc: 0.9667 - loss: 0.1130 - val_acc: 0.9560 - val_loss: 0.1387\n",
      "Epoch 7/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9699 - loss: 0.1027 - val_acc: 0.9553 - val_loss: 0.1377\n",
      "Epoch 8/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9700 - loss: 0.0988 - val_acc: 0.9572 - val_loss: 0.1369\n",
      "Epoch 9/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - acc: 0.9713 - loss: 0.0957 - val_acc: 0.9581 - val_loss: 0.1348\n",
      "Epoch 10/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9740 - loss: 0.0877 - val_acc: 0.9577 - val_loss: 0.1339\n",
      "Epoch 11/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - acc: 0.9725 - loss: 0.0876 - val_acc: 0.9579 - val_loss: 0.1374\n",
      "Epoch 12/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - acc: 0.9751 - loss: 0.0818 - val_acc: 0.9586 - val_loss: 0.1336\n",
      "Epoch 13/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9769 - loss: 0.0779 - val_acc: 0.9607 - val_loss: 0.1304\n",
      "Epoch 14/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9767 - loss: 0.0758 - val_acc: 0.9588 - val_loss: 0.1362\n",
      "Epoch 15/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9770 - loss: 0.0770 - val_acc: 0.9594 - val_loss: 0.1354\n",
      "Epoch 16/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9773 - loss: 0.0734 - val_acc: 0.9608 - val_loss: 0.1313\n",
      "Epoch 17/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - acc: 0.9784 - loss: 0.0698 - val_acc: 0.9607 - val_loss: 0.1342\n",
      "Epoch 18/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - acc: 0.9793 - loss: 0.0683 - val_acc: 0.9603 - val_loss: 0.1329\n",
      "Epoch 19/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9800 - loss: 0.0661 - val_acc: 0.9591 - val_loss: 0.1411\n",
      "Epoch 20/20\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - acc: 0.9793 - loss: 0.0687 - val_acc: 0.9595 - val_loss: 0.1420\n"
     ]
    }
   ],
   "source": [
    "mlpclf2 = models.Model(input_tensor, output_tensor)\n",
    "mlpclf2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['acc'])\n",
    "mlpclf2.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wSMQIbnL2enZ",
   "metadata": {
    "id": "wSMQIbnL2enZ"
   },
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KhpHMwIN29Ka",
   "metadata": {
    "id": "KhpHMwIN29Ka"
   },
   "source": [
    "1. At every node of every tree, the **random forest** algorithm searches for the best split using a **random subset of features**. The number of features is controlled by the parameter `max_features`. We have used the default, which is the square root of the number of columns of the feature matrix (`max_features=sqrt`). This means, in this case, 28 features. Logic tells us that, by increasing `max_features`, we will improve the accuracy, but the learning process (the fit step) will get slower. Try some variations on this, to see how it works in practice. Do you think that using the default number of features here was a good choice?\n",
    "\n",
    "2. Develop a **gradient boosting classifier** for these data, extracted from the `xgboost` class `XGBClassifier()`. Take into account that, with hundreds of columns, a gradient boosting model may be much slower to train than a random forest model with the same tree size and number of trees. A model with 100 trees and a size similar to those shown in this example can take one hour to train (less with XGBoost), though you may find a speed-up by increasing the **learning rate**.\n",
    "\n",
    "3. Develop a **logistic regression classifier** for these data. Compare it with the other models that have appeared in this example.\n",
    "\n",
    "4. Calculate a **confusion matrix** for the logistic regression model (dimension 10x10). Which is the best classified digit? Which is the main source of misclassification?\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
